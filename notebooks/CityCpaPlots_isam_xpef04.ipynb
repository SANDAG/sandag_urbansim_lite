{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append path to find utils module in urbansim\n",
    "import os \n",
    "import sys\n",
    "cwd = os.getcwd() \n",
    "parentdir =  os.path.abspath(os.path.join(cwd, os.pardir))\n",
    "sys.path.append(parentdir) # to get path to utils module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, datetime\n",
    "import numpy as np\n",
    "import utils\n",
    "import orca\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import table\n",
    "import matplotlib.patches as mpatches\n",
    "from sqlalchemy import create_engine\n",
    "from database import get_connection_string\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.patches import Rectangle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection_string = get_connection_string('..\\data\\config.yml', 'mssql_db')\n",
    "mssql_engine = create_engine(db_connection_string)\n",
    "versions = utils.yaml_to_dict('../data/scenario_config.yaml', 'scenario')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get subregional simulation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get max run id from urbansim\n",
    "run_id_sql = '''\n",
    "SELECT max(run_id)\n",
    "  FROM [urbansim].[urbansim].[urbansim_lite_output]\n",
    "'''\n",
    "run_id_df = pd.read_sql(run_id_sql, mssql_engine)\n",
    "run_id = int(run_id_df.values)\n",
    "\n",
    "print(\"\\n   Max run id : {:,}\".format(run_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify run_id?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify run id\n",
    "# run_id = 232\n",
    "# run_id = 109\n",
    "# print(\"\\n  run id specified : {:,}\".format(run_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_change_sql = '''SELECT o.parcel_id,  \n",
    "    unit_change as hs_change, source, capacity_type, year_simulation\n",
    "      FROM urbansim.urbansim.urbansim_lite_output o \n",
    "     WHERE run_id = %s\n",
    "  ORDER BY  year_simulation'''\n",
    "hs_change_sql = hs_change_sql % run_id\n",
    "hs = pd.read_sql(hs_change_sql,mssql_engine)\n",
    "print(\"\\n   Units added: {:,}\".format(int(hs.hs_change.sum())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_sql = '''\n",
    "SELECT  [parcel_id]\n",
    "        ,[jur_id] as jurisdiction_id\n",
    "        ,mgra\n",
    "        ,name\n",
    "      ,[cpa_id] \n",
    "  FROM [isam].[xpef04].[parcel2015_mgra_jur_cpa] c\n",
    "  JOIN urbansim.[ref].[jurisdiction] j on j.jurisdiction_id = c.jur_id\n",
    "  where i = 1'''\n",
    "geo = pd.read_sql(geo_sql,mssql_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### simulation output w geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_geo = pd.merge(hs,geo,left_on='parcel_id',right_on='parcel_id',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### replace sgoa subtypes with 'sgoa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_geo.replace('cc', 'sgoa',inplace=True)\n",
    "hs_geo.replace('mc', 'sgoa',inplace=True)\n",
    "hs_geo.replace('tc', 'sgoa',inplace=True)\n",
    "hs_geo.replace('tco', 'sgoa',inplace=True)\n",
    "hs_geo.replace('uc', 'sgoa',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tablular data\n",
    "estimates_sql = '''\n",
    "SELECT [version_id]\n",
    "      ,[yr]\n",
    "      ,[jurisdiction_name]\n",
    "      ,[jurisdiction_id]\n",
    "      ,[housing_units_add]\n",
    "  FROM [urbansim].[urbansim].[urbansim_target_hu_jur] \n",
    "  WHERE version_id = %s'''\n",
    "estimates_sql = estimates_sql  % versions['target_housing_units_version']\n",
    "estimates_df = pd.read_sql(estimates_sql, mssql_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_2017 = hs_geo.loc[hs_geo.year_simulation==2017].groupby(['jurisdiction_id']).\\\n",
    "                agg({'hs_change': 'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates_qc= pd.merge(hs_2017,estimates_df,on='jurisdiction_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates_qc['diff'] = estimates_qc['hs_change'] - estimates_qc['housing_units_add']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates_qc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get total dwelling units in the region and sum by jurisdiction and cpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### note using cap jurisdiction id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du_sql = '''\n",
    "    SELECT parcel_id, du_2015 as du, du_2017, capacity_2\n",
    "        FROM urbansim.parcel p\n",
    "        WHERE (du_2017 > 0 or du_2015 > 0)'''\n",
    "du = pd.read_sql(du_sql,mssql_engine)\n",
    "du = pd.merge(du,geo,left_on='parcel_id',right_on='parcel_id',how='left')\n",
    "\n",
    "print(\"\\n   Dwelling Units 2015: {:,}\".format(int(du.du.sum())))\n",
    "print(\"\\n   Dwelling Units 2017: {:,}\".format(int(du.du_2017.sum())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get unique CPAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPAs = geo.loc[geo.cpa_id>0].cpa_id.unique().tolist()\n",
    "jurs = geo.jurisdiction_id.unique().tolist()\n",
    "print(\"Number of jurisdictions: {:,}\".format(len(jurs)))\n",
    "print(\"Number of cpas: {:,}\".format(len(CPAs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### set \"jcid\" to be jurisdiction or cpa id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = hs_geo.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units['jcid'] = units['jurisdiction_id']\n",
    "units.loc[units.jurisdiction_id==14,'jcid'] = units['cpa_id']\n",
    "units.loc[units.jurisdiction_id==19,'jcid'] = units['cpa_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dwelling units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dus = du.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dus['jcid'] = dus['jurisdiction_id']\n",
    "dus.loc[dus.jurisdiction_id == 19,'jcid'] = dus['cpa_id']\n",
    "dus.loc[dus.jurisdiction_id == 14,'jcid'] = dus['cpa_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  complete the dataset: for CPAs with no unit change, add unit change equal to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### simulation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.jcid = units.jcid.astype(int)\n",
    "units.parcel_id = units.parcel_id.astype(int)\n",
    "units.set_index('jcid',inplace=True) # necessary for adding missing CPAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jcids = units.index.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(jcids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # necessary for adding missing CPAs\n",
    "CPAs_no_unit_change = np.setdiff1d(CPAs,jcids).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CPAs_no_unit_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need jcid as index here\n",
    "for cpa in CPAs_no_unit_change:\n",
    "    units.loc[cpa] = np.nan\n",
    "units.reset_index(inplace=True) # reset index after assigning CPAs\n",
    "units.fillna(0,inplace=True)\n",
    "len(units.jcid.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set simulation year to '2017' for CPAs that had no housing unit change to complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set year to 2017 for 9 CPAs with no data\n",
    "units.loc[units.year_simulation==0,'year_simulation'] = 2017\n",
    "units.year_simulation = units.year_simulation.astype(int)\n",
    "#units.loc[units.jcid.isin(CPAs_no_unit_change)][['parcel_id','jcid','jurisdiction_id','hs_change',\\\n",
    "#                          'year_simulation']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### set jurisdiction id and cpa id for cpas with no unit change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.loc[units.jcid.isin(CPAs_no_unit_change),'jurisdiction_id' ] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.loc[((units.jcid.isin(CPAs_no_unit_change)) & (units.jcid> 1500)),'jurisdiction_id' ] = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.loc[units.jcid.isin(CPAs_no_unit_change),'cpa_id' ] = \\\n",
    "units.loc[units.jcid.isin(CPAs_no_unit_change)].jcid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# units.loc[units.jcid.isin(CPAs_no_unit_change)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### same for dwelling units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dus.jcid = dus.jcid.astype(int)\n",
    "dus.parcel_id = dus.parcel_id.astype(int)\n",
    "dus.set_index('jcid',inplace=True) # necessary for adding missing CPAs\n",
    "jcids = dus.index.unique().tolist()\n",
    "CPAs_no_unit_change = np.setdiff1d(CPAs,jcids).tolist()\n",
    "CPAs_no_unit_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need jcid as index here\n",
    "for cpa in CPAs_no_unit_change:\n",
    "    dus.loc[cpa] = np.nan\n",
    "dus.reset_index(inplace=True) # reset index after assigning CPAs\n",
    "dus.fillna(0,inplace=True)\n",
    "len(dus.jcid.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add cpa name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update to jcid view\n",
    "cocpa_names_sql = '''\n",
    "    SELECT zone as cpa_id, name as cocpa\n",
    "    FROM data_cafe.ref.geography_zone WHERE geography_type_id = 20'''\n",
    "cocpa_names = pd.read_sql(cocpa_names_sql, mssql_engine)\n",
    "cicpa_names_sql = '''\n",
    "    SELECT zone as cpa_id, name as cicpa\n",
    "    FROM data_cafe.ref.geography_zone WHERE geography_type_id = 15'''\n",
    "cicpa_names = pd.read_sql(cicpa_names_sql, mssql_engine)\n",
    "#jur_name\n",
    "jur_name_sql = '''SELECT [jurisdiction_id],[name] as jur_name FROM [urbansim].[ref].[jurisdiction]'''\n",
    "jur_name = pd.read_sql(jur_name_sql,mssql_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = pd.merge(units,cocpa_names,on='cpa_id',how='left')\n",
    "units = pd.merge(units,cicpa_names,on='cpa_id',how='left')\n",
    "units = pd.merge(units,jur_name,on='jurisdiction_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units['jcname'] = units['jur_name']\n",
    "units.loc[units.jurisdiction_id==14,'jcname'] = units['cicpa']\n",
    "units.loc[units.jurisdiction_id==19,'jcname'] = units['cocpa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.drop(['cocpa', 'cicpa','jur_name','name','cpa_id','jurisdiction_id'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get SR13 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sql = '''\n",
    "select x.mgra, sum([hs]) AS hs, increment, city, cpa, x.luz as luz_id,site\n",
    "from [regional_forecast].[sr13_final].[capacity] x\n",
    "join [regional_forecast].[sr13_final].[mgra13] y\n",
    "on x.mgra = y.mgra\n",
    "where scenario = 0 \n",
    "group by x.mgra, site, increment, y.city,y.cpa,x.luz\n",
    "order by x.mgra, increment'''\n",
    "sr13_df = pd.read_sql(sr13_sql, mssql_engine)\n",
    "# count results\n",
    "nmgra = int(len(sr13_df.mgra.unique()))\n",
    "nincrements = int(len(sr13_df.increment.unique()))\n",
    "lendf = int(len(sr13_df))\n",
    "duplicated_df = sr13_df[sr13_df.duplicated(subset=['mgra','increment'], keep=\"first\")]\n",
    "numdup = int(len(duplicated_df))\n",
    "mi = nmgra*nincrements\n",
    "nodups = lendf - numdup\n",
    "print(\"\\n   Number of increments: {:,}\".format(nincrements))\n",
    "print(\"\\n   Number of mgras: {:,}\".format(nmgra))\n",
    "print(\"\\n        increments * mgras: {:,}\".format(mi))\n",
    "print(\"\\nsr13 dataframe length: {:,}\".format(lendf))\n",
    "print(\"\\n   Number of duplicates: {:,}  (mgra w site id and not site id)\".format(numdup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sr13_df.loc[sr13_df.city==1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get CPAs for city and county for sr13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cicpa_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_df = pd.merge(sr13_df,jur_name[['jurisdiction_id','jur_name']],left_on='city',\\\n",
    "                   right_on='jurisdiction_id')\n",
    "sr13_df = pd.merge(sr13_df,cocpa_names[['cpa_id','cocpa']],left_on='cpa',right_on='cpa_id', how = 'outer')\n",
    "sr13_df = pd.merge(sr13_df,cicpa_names[['cpa_id','cicpa']],left_on='cpa',right_on='cpa_id',how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sr13_df.loc[sr13_df.city==1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_df['jcname'] = sr13_df['jur_name']\n",
    "sr13_df.loc[sr13_df.jurisdiction_id==14,'jcname'] = sr13_df['cicpa']\n",
    "sr13_df.loc[sr13_df.jurisdiction_id==19,'jcname'] = sr13_df['cocpa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_df['jcid'] = sr13_df['cpa']\n",
    "sr13_df.loc[sr13_df.cpa==0,'jcid'] = sr13_df['jurisdiction_id']\n",
    "sr13_df['jcid'] = sr13_df['jcid'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sr13_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_df.drop(['cpa_id_x', 'cpa_id_y', 'cocpa', 'cicpa','luz_id','city','jur_name'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sr13_df['jcid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sr13_df.loc[sr13_df.jcid==1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sum dwelling units by jursidictions and CPAs (n=103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du_sr14_geo_df = dus.groupby(['jcid'])[[\"du\",\"du_2017\"]].sum()\n",
    "du_sr14_geo_df['du_2017'] = du_sr14_geo_df['du_2017'].astype(int)\n",
    "du_sr14_geo_df['du'] = du_sr14_geo_df['du'].astype(int)\n",
    "print(\"\\n Total residential dwelling units 2015: {:,}\".format(int(du_sr14_geo_df.du.sum())))\n",
    "print(\"\\n Total residential dwelling units 2017: {:,}\".format(int(du_sr14_geo_df.du_2017.sum())))\n",
    "print(\"\\n Total number of jurisdictions and cpas: {:,}\\n\".format(len(du_sr14_geo_df.index.unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sum hs change in simulation by jursidictions and CPAs (n=103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_geo_df = pd.DataFrame({'hs_sum': units.groupby(['jcid','jcname','year_simulation']).\\\n",
    "                            hs_change.sum()}).reset_index()\n",
    "sr14_geo_df.rename(columns = {'jcname':'geo'},inplace=True)\n",
    "# sr14_geo_df.rename(columns = {'year_simulation':'increment'},inplace=True)\n",
    "sr14_geo_df.sort_values(by='jcid',inplace=True)\n",
    "sr14_geo_df.set_index('jcid',inplace=True)\n",
    "sr14_geo_df['hs_sum'] = sr14_geo_df['hs_sum'].astype(int)\n",
    "sr14_geo_df['year_simulation'] = sr14_geo_df['year_simulation'].astype(int)\n",
    "print(\"\\n Total housing unit change after groupby: {:,}\".format(int(sr14_geo_df.hs_sum.sum())))\n",
    "print(\"\\n Total number of jurisdictions and cpas: {:,}\\n\".format(len(sr14_geo_df.index.unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sum simulation output by source (fill NA with \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_source = pd.DataFrame({'hs_sum': units.groupby(['source','jcid','jcname']).\\\n",
    "                            hs_change.sum()}).reset_index()\n",
    "sr14_source.rename(columns = {'jcname':'geo'},inplace=True)\n",
    "sr14_source.sort_values(by='jcid',inplace=True)\n",
    "sr14_source.set_index('jcid',inplace=True)\n",
    "sr14_source['hs_sum'] = sr14_source['hs_sum'].astype(int)\n",
    "print(\"\\n Total housing unit change after groupby: {:,}\".format(int(sr14_source.hs_sum.sum())))\n",
    "print(\"\\n Total number of jurisdictions and cpas: {:,}\\n\".format(len(sr14_source.index.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = range(1,4)\n",
    "sr14_source.set_index(['geo','source'],append=True,inplace=True)\n",
    "sr14_source = sr14_source.unstack(['jcid','geo'])\n",
    "# sr14_source = sr14_source.reindex(idx, fill_value=0)\n",
    "sr14_source.fillna(0,inplace=True)\n",
    "sr14_source = sr14_source.stack(['jcid','geo'])\n",
    "sr14_source.reset_index(inplace=True)\n",
    "sr14_source.set_index('jcid',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_source.source.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_source.loc[sr14_source.geo=='Carlsbad']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sched dev totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_source1 =  sr14_source.loc[sr14_source.source==1.0].copy()\n",
    "sr14_source1.head(5)\n",
    "print(sr14_source1.hs_sum.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get SR13 sched dev totals by jur and cpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev_sql = '''\n",
    "SELECT x.mgra,city, cpa, x.luz as luz_id,site, sum(siteSF+siteMF+siteMH) AS sched_dev\n",
    "FROM [regional_forecast].[sr13_final].[capacity] x\n",
    "join [regional_forecast].[sr13_final].[mgra13] y\n",
    "on x.mgra = y.mgra\n",
    "where scenario = 0 and increment = 2050 and site != 0 and (siteSF + siteMF + siteMH) > 0 \n",
    "group by x.mgra, site, increment, y.city,y.cpa,x.luz\n",
    "order by city,site'''\n",
    "sr13_sched_dev = pd.read_sql(sr13_sched_dev_sql, mssql_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev.sched_dev.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev = pd.merge(sr13_sched_dev,jur_name[['jurisdiction_id','jur_name']],left_on='city',\\\n",
    "                   right_on='jurisdiction_id',how='outer')\n",
    "cocpa_names.rename(columns = {'cpa_id':'county_cpa'},inplace=True)\n",
    "cicpa_names.rename(columns = {'cpa_id':'city_cpa'},inplace=True)\n",
    "sr13_sched_dev = pd.merge(sr13_sched_dev,cocpa_names,left_on='cpa',right_on='county_cpa', how = 'outer')\n",
    "sr13_sched_dev = pd.merge(sr13_sched_dev,cicpa_names,left_on='cpa',right_on='city_cpa',how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sr13_sched_dev.loc[sr13_sched_dev['cpa'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sr13_sched_dev.loc[sr13_sched_dev.cpa.isnull(),'jurisdiction_id'] = 14\n",
    "sr13_sched_dev.loc[((sr13_sched_dev.jurisdiction_id.isnull()) & \\\n",
    "                    (~sr13_sched_dev.county_cpa.isnull())),'jurisdiction_id']=19\n",
    "sr13_sched_dev.loc[((sr13_sched_dev.jurisdiction_id.isnull()) & \\\n",
    "                    (~sr13_sched_dev.city_cpa.isnull())),'jurisdiction_id']=14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev.loc[sr13_sched_dev.jurisdiction_id==8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev['jcname'] = sr13_sched_dev['jur_name']\n",
    "sr13_sched_dev.loc[sr13_sched_dev.jurisdiction_id==14,'jcname'] = sr13_sched_dev['cicpa']\n",
    "sr13_sched_dev.loc[sr13_sched_dev.jurisdiction_id==19,'jcname'] = sr13_sched_dev['cocpa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sr13_sched_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev['jcid'] = sr13_sched_dev['cpa']\n",
    "sr13_sched_dev.loc[sr13_sched_dev.cpa==0,'jcid'] = sr13_sched_dev['jurisdiction_id']\n",
    "sr13_sched_dev.loc[sr13_sched_dev.jcid.isnull(),'jcid'] = sr13_sched_dev['county_cpa']\n",
    "sr13_sched_dev.loc[sr13_sched_dev.jcid.isnull(),'jcid'] = sr13_sched_dev['city_cpa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sr13_sched_dev.loc[sr13_sched_dev.jcid.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev['jcid'] = sr13_sched_dev['jcid'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sr13_sched_dev.loc[sr13_sched_dev['jcid'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sr13_sched_dev.rename(columns = {'jcid':'geo'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev['geo'] = sr13_sched_dev['jcname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev.drop(['jurisdiction_id', 'city_cpa', 'county_cpa', 'cocpa', 'cicpa'], axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev_totals = pd.DataFrame({'sched_dev_sum': sr13_sched_dev.\n",
    "                                            groupby([\"jcid\",'geo']).\n",
    "                                 sched_dev.sum()}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev_totals.sched_dev_sum.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in \"0\" for units for \"missing\" simulation years (for plotting) (e.g. Del Mar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Del Mar example\n",
    "del_mar_before = sr14_geo_df.loc[4].sort_values(by='year_simulation')\n",
    "# del_mar_before.head()\n",
    "del_mar_before.plot(x='year_simulation',y='hs_sum',style='.-',title='NULL values in Del Mar Housing Unit Change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del_mar_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = range(2017,2051)\n",
    "sr14_geo_df.set_index(['geo','year_simulation'],append=True,inplace=True)\n",
    "sr14_geo_df = sr14_geo_df.unstack(['jcid','geo'])\n",
    "sr14_geo_df = sr14_geo_df.reindex(idx, fill_value=0)\n",
    "sr14_geo_df.fillna(0,inplace=True)\n",
    "sr14_geo_df = sr14_geo_df.stack(['jcid','geo'])\n",
    "sr14_geo_df.reset_index(inplace=True)\n",
    "sr14_geo_df.set_index('jcid',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_mar_after = sr14_geo_df.loc[4].sort_values(by='year_simulation')\n",
    "del_mar_after.plot(x='year_simulation',y='hs_sum',style='.-',title='Replace Null with Zeroes Del Mar Housing Unit Change')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum units from output of simulation over five year increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = range(2015,2055,5)\n",
    "names = [str(x) for x in range(2020,2055,5)]\n",
    "sr14_geo_df['increment'] = pd.cut(sr14_geo_df.year_simulation, bins, labels=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_increment = pd.DataFrame({'hs_increment': sr14_geo_df.\n",
    "                                            groupby([\"increment\",\"jcid\",\"geo\"]).\n",
    "                                 hs_sum.sum()}).reset_index()\n",
    "# sr14_increment.set_index('jcid',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_increment.increment = sr14_increment.increment.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative sum units added by increment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_increment['hs_cumulative'] = sr14_increment.groupby(['geo'])['hs_increment'].apply(lambda x: x.cumsum())\n",
    "sr14_increment.set_index('jcid',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join simulation output with existing dwelling units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14 = sr14_increment.join(du_sr14_geo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14['hs'] = sr14['hs_cumulative'] + sr14['du_2017']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add increment 2016 with units added equal to zero for baseline du (for plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = sr14_geo_df.loc[sr14_geo_df.year_simulation==2017].copy()\n",
    "len(start_year)\n",
    "start_year['increment'] = 2015\n",
    "start_year = start_year.join(du_sr14_geo_df)\n",
    "start_year['hs'] = start_year['du']\n",
    "start_year['year_simulation'] = 'baseline'\n",
    "sr14 = pd.concat([sr14,start_year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year['increment'] = 2017\n",
    "start_year['hs'] = start_year['du_2017']\n",
    "sr14 = pd.concat([sr14,start_year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sr14.loc[1420].sort_values(by='increment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SR13 aggregrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  mgra level housing to cpa and jurisdiction and group by increment and sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_geo_df = pd.DataFrame({'hs_sum': sr13_df.groupby(['jcname','jcid','increment']).\n",
    "                               hs.sum()}).reset_index()\n",
    "sr13_geo_df.rename(columns = {'jcname':'geo'},inplace=True)\n",
    "sr13_geo_df.sort_values(by='jcid',inplace=True)\n",
    "#sr13_geo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sr13_geo_df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNum of geographies (jurisdiction plus cpa) = {:,}\\n\".format(int(len(sr13_geo_df.loc[sr13_geo_df.increment==2015]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  sr13 pivot so each jurisdiction or cpa is column and rows are increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_geo_df_pivot = sr13_geo_df.pivot\\\n",
    "(index='increment', columns='geo', values='hs_sum').\\\n",
    "reset_index().rename_axis(None, axis=1)\n",
    "sr13_geo_df_pivot.set_index('increment',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sr13_geo_df_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  sr14 pivot so each jurisdiction or cpa is column and rows are increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sr14.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sr14.to_csv('test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_geo_df_pivot = sr14.pivot\\\n",
    "(index='increment', columns='geo', values='hs').\\\n",
    "reset_index().rename_axis(None, axis=1)\n",
    "sr14_geo_df_pivot.set_index('increment',inplace=True)\n",
    "sr14_geo_df_pivot.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sr14_geo_df_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  sr13 calculate total change by region and jurisdiction and cpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_diff = sr13_geo_df_pivot.loc[[2012,2050],:]\n",
    "differences = total_diff.diff().loc[[2050]]\n",
    "differences.rename(index={2050: 'total_change'},inplace=True)\n",
    "totalchange = pd.DataFrame(differences.sum(axis=0))\n",
    "totalchange.rename(columns={0: 'total_change'},inplace=True)\n",
    "sr13_totalchange = pd.DataFrame(differences.sum(axis=0))\n",
    "sr13_totalchange.rename(columns={0: 'total_change'},inplace=True)\n",
    "print(\"\\nTotal Units added sr13: {:,}\".format(int(totalchange.total_change.sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolist = sr14_geo_df.geo.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for jur in (geolist):\n",
    "    s = str(jur)\n",
    "    l.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print '[%s]' % ', '.join(map(str, l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### directory for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = os.path.join(os.getcwd(),'plots/run'+str(run_id))#,datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "                       \n",
    "                       # 'run_'+str(run_id) + '_city_cpa')\n",
    "                         \n",
    "try:\n",
    "    os.stat(dirname)\n",
    "except:\n",
    "    os.mkdir(dirname)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolist[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jur = 'Carlsbad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev_totals.loc[ sr13_sched_dev_totals['geo']==jur]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev_totals.loc[ sr13_sched_dev_totals['geo']==jur].iloc[0]['sched_dev_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sr13_sched_dev_totals['geo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot figures as png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheddevlabel_sr13 = '(' + str(int( sr13_sched_dev_totals.loc[ sr13_sched_dev_totals['geo']==jur].iloc[0]['sched_dev_sum'])) + ' sched dev)'    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_source1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheddevlabel = '(' + str(int(sr14_source1.loc[sr14_source1['geo']==jur].iloc[0]['hs_sum'])) + ' sched dev)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_geo_df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sr14_increments_int = sr14_geo_df_pivot[[jur]].reset_index().increment.tolist()\n",
    "sr13_increments_int = sr13_geo_df_pivot[[jur]].reset_index().increment.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COPY\n",
    "for j, jur in enumerate(geolist):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        chg = int(sr14_increment.loc[(sr14_increment.increment==2050) & (sr14_increment.geo==jur)].hs_cumulative)\n",
    "        plotlabelsr13 = 'sr13 '\n",
    "        plotlabelsr14 = 'sr14 '\n",
    "        scheddevlabel_sr13 = '(' + str(int( sr13_sched_dev_totals.loc[ sr13_sched_dev_totals['geo']==jur].iloc[0]['sched_dev_sum'])) + ' sched dev)'    \n",
    "        scheddevlabel = '(' + str(int(sr14_source1.loc[sr14_source1['geo']==jur].iloc[0]['hs_sum'])) + ' sched dev)'\n",
    "        sr14_increments_int = sr14_geo_df_pivot[[jur]].reset_index().increment.tolist()\n",
    "        sr13_increments_int = sr13_geo_df_pivot[[jur]].reset_index().increment.tolist()\n",
    "        \n",
    "        \n",
    "        sr14 = ax.plot(sr14_increments_int,\n",
    "                       sr14_geo_df_pivot[[jur]].reset_index()[jur].tolist(),'b-o')\n",
    "        sr13 = plt.plot(sr13_increments_int,\n",
    "                        sr13_geo_df_pivot[[jur]].reset_index()[jur].tolist(),'r-o')\n",
    "          \n",
    "        city_cpa_id = str(sr14_geo_df.loc[sr14_geo_df['geo']==jur].index.values[0])  \n",
    "       \n",
    "        # legendtitle = jur + ' (' +  city_cpa_id + ')'\n",
    "\n",
    "                \n",
    "        # create blank rectangle\n",
    "        extra = Rectangle((0, 0), 1, 1, fc=\"w\", fill=False, edgecolor='none', linewidth=0)\n",
    "        ax.legend([sr14[0],sr13[0]],\\\n",
    "                  (plotlabelsr14,plotlabelsr13))\n",
    "        # extra2 = Rectangle((0, 0), 1, 1, fc=\"w\", fill=False, edgecolor='none', linewidth=0)\n",
    "        # extra3 = Rectangle((0, 0), 1, 1, fc=\"w\", fill=False, edgecolor='none', linewidth=0)\n",
    "        # ax.legend([extra, sr13[0],extra2,sr14[0],extra3], (\"Total Chg\", plotlabelsr13,scheddevlabel_sr13, plotlabelsr14,scheddevlabel))\n",
    "        # plt.ylabel('Housing stock')\n",
    "        # plt.xlabel('Year')\n",
    "        # plt.title('Series 13 and DRAFT Series 14 Comparison\\n' + jur + ' (id=' +  city_cpa_id + ')')\n",
    "        ptitle = 'DRAFT Series 14 and Series 13 Comparison\\n' + jur + ' (id=' +  str(city_cpa_id) + ')'\n",
    "        ax.set_title(ptitle,fontsize= 14)\n",
    "        ax.set_xlabel(\"Year\",size=14)\n",
    "        ax.set_ylabel(\"Housing stock\",size=14)\n",
    "        # ptitle = 'DRAFT Cumulative Housing Units Added By Capacity Type\\n' + jur + ' (id=' +  str(city_cpa_id) + ')'\n",
    "        jur_ = jur.replace(\":\", \"_\") # colon not allowed in windows filename\n",
    "        plotname = dirname + '//' + 'city_cpa_' + city_cpa_id + '_' + jur_ + '.png'\n",
    "        # plotname = dirname + '//' + str(run_id) + '_city_cpa_' + city_cpa_id + '_' + jur_ + '.png'\n",
    "\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(6, 4.5)\n",
    "        fig.savefig(plotname, bbox_inches='tight',dpi=200)\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "        \n",
    "        \n",
    "        # ptitle = 'DRAFT Cumulative Housing Units Added By Capacity Type\\n' + jur + ' (id=' +  str(city_cpa_id) + ')'\n",
    "        # ax.set_ylabel(\"housing units added\",size=14)\n",
    "        # ax.set_title(ptitle,size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev_totals.loc[ sr13_sched_dev_totals['geo']==jur]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  AS PDF instead of png"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# pp = PdfPages(\"out/sr13_and_draft_sr14_compare_3_w_2controlsb.pdf\")# \n",
    "# pdfdirname = os.path.join(os.getcwd(),'plots') ,datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "# pdfplotname = pdfdirname + '//' + str(run_id) + '_city_cpa_' + str(j+1) + '_' +\\\n",
    "#              datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')) + '.pdf'\n",
    "# pp = PdfPages(pdfplotname)\n",
    "\n",
    "\n",
    "# for j, jur in enumerate(sr14_geo_df.geo.unique().tolist()):\n",
    "# for j, jur in  enumerate(['Carlsbad','Chula Vista']):\n",
    "#    chg = int(sr14_increment.loc[(sr14_increment.increment=='2050') & (sr14_increment.geo==jur)].hs_cumulative)\n",
    "#    jur_and_cpa_plot = plt.figure()\n",
    "    # plt.subplot(20, 1, j+1)\n",
    "    # plotlabel = jur + '\\nchg = ' + str(int(totalchange.loc[jur][0]))\n",
    "#    plotlabelsr14 = 'sr14: '+ str(sr14_geo_df.loc[sr14_geo_df['geo']==jur].index.values[0]) + '.' +\\\n",
    "#                jur + '\\nchg = ' + str(chg) + '\\n(sched dev = ' + \\\n",
    "#                str(int(sr14_source1.loc[sr14_source1['geo']==jur].iloc[0]['hs_sum'])) + ')'\n",
    "#    plotlabelsr13 = 'sr13: ' + str(sr13_geo_df.loc[sr13_geo_df['geo']==jur].jur_or_cpa_id.values[0]) + '.' +\\\n",
    "#                jur + '\\nchg = ' + str(int(totalchange.loc[jur][0]))\n",
    "    \n",
    "    #plt.plot(sr14_geo_df_pivot[[jur]].reset_index().increment.tolist(),sr14_geo_df_pivot[[jur]].reset_index()[jur].tolist(),\n",
    "            # label=plotlabelsr14,\n",
    "    #         sr13_geo_df_pivot[[jur]].reset_index().increment.tolist(),sr13_geo_df_pivot[[jur]].reset_index()[jur].tolist(),\n",
    "     #        label=plotlabelsr13\n",
    "     #       )\n",
    "#    plt.plot(sr14_geo_df_pivot[[jur]].reset_index().increment.tolist(),\n",
    "#             sr14_geo_df_pivot[[jur]].reset_index()[jur].tolist(),'b-o', label=plotlabelsr14)\n",
    "#    plt.plot(sr13_geo_df_pivot[[jur]].reset_index().increment.tolist(),\n",
    "#             sr13_geo_df_pivot[[jur]].reset_index()[jur].tolist(),'r-o', label=plotlabelsr13)\n",
    "#    plt.legend()\n",
    "#    plt.ylabel('Housing stock')\n",
    "#    plt.xlabel('Increment')\n",
    "#    plt.title('Series 13 and Draft Series 14\\n   at Jurisdiction and CPA')\n",
    "#    pp.savefig(jur_and_cpa_plot, dpi = 300, transparent = True)\n",
    "# pp.close()\n",
    "# plt.savefig('sr13_jur_and_cpa.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "units_added_by_source.plot(style='.-',stacked=True,kind='bar',ax=axes.flat[2],\\\n",
    "                           figsize=(10,15),color=['red','purple','green','sandybrown'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# QC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = range(2015,2055,5)\n",
    "names = [str(x) for x in range(2020,2055,5)]\n",
    "units['increment'] = pd.cut(units.year_simulation, bins, labels=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \"jcid\",\"geo\"\n",
    "units_added_by_capacity_type_and_yr = pd.DataFrame({'units_by_type': units.\n",
    "                                          groupby([\"jcid\",\"jcname\",\"increment\",\"capacity_type\"])\n",
    "                                          .hs_change.sum()}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolist = units_added_by_capacity_type_and_yr.jcname.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geolist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_added_by_capacity_type_and_yr.set_index(['jcid','jcname','increment','capacity_type'],inplace=True)\n",
    "units_added_by_capacity_type_and_yr = units_added_by_capacity_type_and_yr.unstack(['jcid','jcname'])\n",
    "units_added_by_capacity_type_and_yr.fillna(0,inplace=True)\n",
    "units_added_by_capacity_type_and_yr = units_added_by_capacity_type_and_yr.stack(['jcid','jcname'])\n",
    "units_added_by_capacity_type_and_yr.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tablular data\n",
    "assigned_parcel_sql = '''\n",
    "SELECT  a.parcel_id,  a.du, a.type\n",
    "   FROM [urbansim].[urbansim].[additional_capacity] a\n",
    "  WHERE version_id = %s'''\n",
    "assigned_parcel_sql = assigned_parcel_sql % versions['additional_capacity_version']\n",
    "assigned_df = pd.read_sql(assigned_parcel_sql, mssql_engine)\n",
    "assigned_df.replace('cc', 'sgoa',inplace=True)\n",
    "assigned_df.replace('mc', 'sgoa',inplace=True)\n",
    "assigned_df.replace('tc', 'sgoa',inplace=True)\n",
    "assigned_df.replace('tco', 'sgoa',inplace=True)\n",
    "assigned_df.replace('uc', 'sgoa',inplace=True)\n",
    "\n",
    "# assigned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tablular data\n",
    "assignedcpa = pd.merge(assigned_df,geo,left_on='parcel_id',right_on='parcel_id',how='left')\n",
    "assignedcpa.loc[assignedcpa.jurisdiction_id == 19,'jcid'] = assignedcpa['cpa_id']\n",
    "assignedcpa.loc[assignedcpa.jurisdiction_id == 14,'jcid'] = assignedcpa['cpa_id']\n",
    "assignedcpa['jcid'].fillna(assignedcpa['jurisdiction_id'],inplace=True)\n",
    "#assignedcpa.loc[assignedcpa.mgra_id==19415,'jcid'] = 1909\n",
    "#assignedcpa.loc[assignedcpa.mgra_id==18831,'jcid'] = 1909\n",
    "#assignedcpa.loc[assignedcpa.mgra_id==11514.0,'jcid'] = 13\n",
    "#assignedcpa.loc[assignedcpa.mgra_id==7521.0,'jcid'] = 3\n",
    "#assignedcpa.loc[assignedcpa.mgra_13==7259,'jcid'] = 1439 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tablular data\n",
    "sched_dev_parcel_sql = '''\n",
    "SELECT s.parcel_id,capacity_3\n",
    "FROM [urbansim].[urbansim].[scheduled_development_parcel] s'''\n",
    "sched_dev_df = pd.read_sql(sched_dev_parcel_sql, mssql_engine)\n",
    "sched_dev_capacity = int(sched_dev_df.capacity_3.sum())\n",
    "print(\"\\nScheduled development capacity from urbansim.scheduled_development_parcel : {:,}\".\\\n",
    "      format(sched_dev_capacity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tablular data\n",
    "sunits = pd.merge(sched_dev_df,geo,left_on='parcel_id',right_on='parcel_id',how='left')\n",
    "sunits.loc[sunits.jurisdiction_id == 19,'jcid'] = sunits['cpa_id']\n",
    "sunits.loc[sunits.jurisdiction_id == 14,'jcid'] = sunits['cpa_id']\n",
    "sunits['jcid'].fillna(sunits['jurisdiction_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tablular data\n",
    "parcel_capacity_sql = '''\n",
    "    SELECT [parcel_id],[site_id],\n",
    "           [du_2015],[du_2017],[capacity_1],[capacity_2]\n",
    "      FROM [urbansim].[urbansim].[parcel]'''\n",
    "capacity_df = pd.read_sql(parcel_capacity_sql,mssql_engine)\n",
    "urbansim_parcel_capacity = int(capacity_df.loc[((capacity_df.site_id.isnull()) | (capacity_df.site_id==15008))].\\\n",
    "                               capacity_2.sum())\n",
    "# ([site_id] IS NULL or site_id = 15008)\n",
    "print(\"\\nCapacity from urbansim.parcel where site id is null: {:,}\".format(urbansim_parcel_capacity))\n",
    "# 291,989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tablular data\n",
    "urb_parcel_units = pd.merge(capacity_df,geo,left_on='parcel_id',right_on='parcel_id',how='left')\n",
    "urb_parcel_units.loc[urb_parcel_units.jurisdiction_id == 19,'jcid'] = urb_parcel_units['cpa_id']\n",
    "urb_parcel_units.loc[urb_parcel_units.jurisdiction_id == 14,'jcid'] = urb_parcel_units['cpa_id']\n",
    "urb_parcel_units['jcid'].fillna(urb_parcel_units['jurisdiction_id'],inplace=True)\n",
    "print(len(urb_parcel_units))\n",
    "print(len(capacity_df))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\"\\nRun id : {:,}\".format(run_id))\n",
    "\n",
    "hs_change_sql = '''\n",
    "    SELECT o.parcel_id, j.name,  p.cap_jurisdiction_id, p.jurisdiction_id, p.mgra_id, p.luz_id,\n",
    "    unit_change as hs_change, source, capacity_type,year_simulation\n",
    "      FROM urbansim.urbansim.urbansim_lite_output o \n",
    "      JOIN urbansim.urbansim.parcel p on p.parcel_id = o.parcel_id\n",
    "      JOIN urbansim.ref.jurisdiction j on p.cap_jurisdiction_id = j.jurisdiction_id\n",
    "     WHERE run_id =  %s\n",
    "  ORDER BY j.name,p.jurisdiction_id, year_simulation'''\n",
    "hs_change_sql = hs_change_sql % run_id\n",
    "hs = pd.read_sql(hs_change_sql,mssql_engine)\n",
    "units_added = int(hs.hs_change.sum())\n",
    "\n",
    "print(\"\\nUnits added: {:,} \".\\\n",
    "      format(units_added))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# for tablular data\n",
    "hscpa = pd.merge(hs,xref_geography_df,left_on='mgra_id',right_on='mgra_13',how='left')\n",
    "hscpa.loc[hscpa.cap_jurisdiction_id == 19,'jcid'] = hscpa['cocpa_2016']\n",
    "hscpa.loc[hscpa.cap_jurisdiction_id == 14,'jcid'] = hscpa['cicpa_13']\n",
    "hscpa['jcid'].fillna(hscpa['cap_jurisdiction_id'],inplace=True)\n",
    "hscpa.loc[hscpa.mgra_id==19415,'jcid'] = 1909\n",
    "hscpa.loc[hscpa.mgra_id==18831,'jcid'] = 1909\n",
    "hscpa.loc[hscpa.mgra_id==11514.0,'jcid'] = 13\n",
    "hscpa.loc[hscpa.mgra_id==7521.0,'jcid'] = 3\n",
    "hscpa.loc[hscpa.mgra_13==7259,'jcid'] = 1439 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use this for bar plots and tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, jur in enumerate(geolist):\n",
    "    c = units_added_by_capacity_type_and_yr.loc[units_added_by_capacity_type_and_yr.jcname==jur]\n",
    "    type_pivot = c.pivot(index='increment', columns='capacity_type', values='units_by_type').\\\n",
    "    reset_index().rename_axis(None, axis=1)\n",
    "    \n",
    "    type_pivot.set_index('increment',inplace=True)\n",
    "    type_pivot.fillna(0,inplace=True)\n",
    "    type_pivot = type_pivot[['sch', 'jur', 'adu', 'sgoa']]\n",
    "    type_pivot['sch'] = type_pivot['sch'].cumsum()\n",
    "    type_pivot['jur'] = type_pivot['jur'].cumsum()\n",
    "    type_pivot['adu'] = type_pivot['adu'].cumsum()\n",
    "    type_pivot['sgoa'] = type_pivot['sgoa'].cumsum()\n",
    "    \n",
    "    city_cpa_id = c.iloc[0]['jcid']\n",
    "    \n",
    "    ax = type_pivot.plot.bar(stacked=True,rot=0)\n",
    "    \n",
    "    ptitle = 'DRAFT Cumulative Housing Units Added By Capacity Type\\n' + jur + ' (id=' +  str(city_cpa_id) + ')'\n",
    "    ax.set_ylabel(\"Housing units added\",size=14)\n",
    "    ax.set_title(ptitle,size=14)\n",
    "    ax.set_xlabel(\"Year\",size=14)\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(6, 4.5)\n",
    "    jur_ = jur.replace(\":\", \"_\") # colon not allowed in windows filename\n",
    "    plotname = dirname + '//' + 'city_cpa_' + str(city_cpa_id) + '_' + jur_ + 'bar.png'\n",
    "    fig.savefig(plotname, bbox_inches='tight',dpi=200)\n",
    "    #plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the right table in the pp\n",
    "df=pd.DataFrame()\n",
    "for j, jur in enumerate(geolist):\n",
    "    jur_ = jur.replace(\":\", \"_\")  # colon not allowed in windows filename\n",
    "    c = units_added_by_capacity_type_and_yr.loc[units_added_by_capacity_type_and_yr.jcname==jur]\n",
    "    type_pivot = c.pivot(index='increment', columns='capacity_type', values='units_by_type').\\\n",
    "        reset_index().rename_axis(None, axis=1)\n",
    "    city_cpa_id = c.iloc[0]['jcid']\n",
    "    hs_1 = units.loc[units.jcid==city_cpa_id]\n",
    "    units_added = int(hs_1.hs_change.sum())\n",
    "    \n",
    "    type_pivot.set_index('increment',inplace=True)\n",
    "    type_pivot.fillna(0,inplace=True)\n",
    "    type_pivot = type_pivot[['sch', 'jur', 'adu', 'sgoa']]\n",
    "    sum_sgoa = int(type_pivot.sgoa.sum())\n",
    "    sum_adu = int(type_pivot.adu.sum())\n",
    "    sum_jur = int(type_pivot.jur.sum())\n",
    "    sum_sch = int(type_pivot.sch.sum())\n",
    "    \n",
    "    type_pivot.sgoa.fillna(0,inplace=True)\n",
    "    type_pivot.adu.fillna(0,inplace=True)\n",
    "    type_pivot.jur.fillna(0,inplace=True)\n",
    "    type_pivot.sch.fillna(0,inplace=True)\n",
    "    if units_added == 0:\n",
    "        percent_total = str(0) + '%'\n",
    "        percent_sch = str(0) + '%'\n",
    "        percent_jur = str(0) + '%'\n",
    "        percent_provided = str(0) + '%'\n",
    "        percent_adu = str(0) + '%'\n",
    "        percent_sgoa = str(0) + '%'\n",
    "        percent_additional = str(0) + '%'\n",
    "    else:\n",
    "        percent_total = str(round(units_added/units_added * 100)) + '%'\n",
    "        percent_sch = str(round(sum_sch/units_added * 100)) + '%'\n",
    "        percent_jur = str(round(sum_jur/units_added * 100)) + '%'\n",
    "        percent_provided = str(round((sum_sch+sum_jur)/units_added * 100)) + '%'\n",
    "        percent_adu = str(round(sum_adu/units_added * 100)) + '%'\n",
    "        percent_sgoa = str(round(sum_sgoa/units_added * 100)) + '%'\n",
    "        percent_additional = str(round((sum_adu+sum_sgoa)/units_added * 100)) + '%'\n",
    "        \n",
    "    assigned_df_1 = assignedcpa.loc[assignedcpa.jcid==city_cpa_id]\n",
    "    assigned_capacity_1 = int(assigned_df_1.du.sum())\n",
    "    assigned_capacity_adu = int(assigned_df_1.loc[assigned_df.type=='adu'].du.sum())\n",
    "    assigned_capacity_sgoa = int(assigned_df_1.loc[assigned_df.type=='sgoa'].du.sum())\n",
    "    sched_dev_df_1 = sunits.loc[sunits.jcid==city_cpa_id]\n",
    "    sched_dev_capacity_1 = int(sched_dev_df_1.capacity_3.sum())\n",
    "    capacity_df_1 = urb_parcel_units.loc[urb_parcel_units.jcid==city_cpa_id]\n",
    "    urbansim_parcel_capacity_1 = int(capacity_df_1.loc[((capacity_df_1.site_id.isnull()) | (capacity_df_1.site_id==15008))].\\\n",
    "                                     capacity_2.sum())\n",
    "    \n",
    "    # urbansim_parcel_capacity = int(capacity_df.loc[((capacity_df.site_id.isnull()) | (capacity_df.site_id==15008))].\\\n",
    "    #                           capacity_2.sum())\n",
    "    \n",
    "    total_capacity_1 = assigned_capacity_1 + sched_dev_capacity_1 + urbansim_parcel_capacity_1\n",
    "    remaining_total = total_capacity_1 - units_added\n",
    "    remaining_sch = sched_dev_capacity_1 - sum_sch\n",
    "    remaining_jur = urbansim_parcel_capacity_1 - sum_jur\n",
    "    remaining_adu = assigned_capacity_adu - sum_adu\n",
    "    remaining_sgoa = assigned_capacity_sgoa - sum_sgoa\n",
    "    \n",
    "    share_count = pd.DataFrame({'Total Units Added': [units_added, (sum_sch + sum_jur), sum_sch, sum_jur, \\\n",
    "                                                      (sum_adu + sum_sgoa), sum_adu, sum_sgoa], \\\n",
    "                                'Percentage Units Added': [percent_total, percent_provided, percent_sch, percent_jur, \\\n",
    "                                                           percent_additional, percent_adu, percent_sgoa], \\\n",
    "                                'Total Capacity': [total_capacity_1, (sched_dev_capacity_1 + urbansim_parcel_capacity_1), \\\n",
    "                                                   sched_dev_capacity_1, urbansim_parcel_capacity_1, \\\n",
    "                                                   (assigned_capacity_adu + assigned_capacity_sgoa), assigned_capacity_adu, \\\n",
    "                                                   assigned_capacity_sgoa], \\\n",
    "                                'Remaining Capacity': [remaining_total, (remaining_sch + remaining_jur), remaining_sch, \\\n",
    "                                                       remaining_jur, (remaining_adu + remaining_sgoa), remaining_adu, \\\n",
    "                                                       remaining_sgoa]}, \\\n",
    "                               index=['Total Capacity', '+  Jurisdiction Provided Capacity', '     -  Scheduled Development', \\\n",
    "                                      '     -  Not Scheduled Development', '+  Additional Capacity', \\\n",
    "                                      '     -  Additional Dwelling Units', '     -  SGOA Additional Capacity'])\n",
    "        \n",
    "    cols = ['Total Units Added','Percentage Units Added','Total Capacity','Remaining Capacity']\n",
    "    share_count = share_count[cols] \n",
    "    share_count.index.name = 'Housing Units by Capacity Type'\n",
    "    fig, ax = plt.subplots(figsize=(12, 4)) # set size frame\n",
    "    ax.xaxis.set_visible(False)  # hide the x axis\n",
    "    ax.yaxis.set_visible(False)  # hide the y axis\n",
    "    ax.set_frame_on(False)  # no visible frame, uncomment if size is ok\n",
    "    tabla = table(ax, share_count, loc='upper right', colWidths=[0.18, 0.25, 0.16, 0.20])  \n",
    "    # colWidths=[0.22]*len(share_count.columns)\n",
    "    tabla.auto_set_font_size(False) # Activate set fontsize manually\n",
    "    tabla.set_fontsize(12) # if ++fontsize is necessary ++colWidths\n",
    "    #tabla.scale(1.2, 1.2) # change size table\n",
    "    tabla.scale(1, 4)\n",
    "    \n",
    "    plotname = dirname + '//' + 'city_cpa_' + str(city_cpa_id) + '_' + jur_ + 'percent_capacity_type_table.png'\n",
    "    \n",
    "    plt.savefig(plotname, bbox_inches=\"tight\",transparent=True)\n",
    "    plt.close(fig)\n",
    "    share_count['jur'] = jur\n",
    "    share_count['id'] = city_cpa_id\n",
    "    df = df.append(share_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_cpa_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(index={'+  Jurisdiction Provided Capacity': '      Jurisdiction Provided Capacity'},inplace=True)\n",
    "df.rename(index={'+  Additional Capacity': '      Additional Capacity'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('share_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Remaining Capacity'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.index=='Total Capacity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the left table in the pp\n",
    "for j, jur in enumerate(geolist):\n",
    "    jur_ = jur.replace(\":\", \"_\")  # colon not allowed in windows filename\n",
    "    c = units_added_by_capacity_type_and_yr.loc[units_added_by_capacity_type_and_yr.jcname==jur]\n",
    "    type_pivot = c.pivot(index='increment', columns='capacity_type', values='units_by_type').\\\n",
    "        reset_index().rename_axis(None, axis=1)\n",
    "    city_cpa_id = c.iloc[0]['jcid']\n",
    "    \n",
    "    type_pivot.set_index('increment',inplace=True)\n",
    "    type_pivot.fillna(0,inplace=True)\n",
    "    type_pivot = type_pivot[['sch', 'jur', 'adu', 'sgoa']]\n",
    "    sum_sgoa = int(type_pivot.sgoa.sum())\n",
    "    sum_adu = int(type_pivot.adu.sum())\n",
    "    sum_jur = int(type_pivot.jur.sum())\n",
    "    sum_sch = int(type_pivot.sch.sum())\n",
    "    \n",
    "    # sr14_geo_df_pivot[[jur]]\n",
    "    # sr13_geo_df_pivot[[jur]]\n",
    "    hs_base_sr13 = int(sr13_geo_df_pivot[[jur]].loc[2012].values[0])\n",
    "    hs_base_sr14 = int(sr14_geo_df_pivot[[jur]].loc[2017].values[0])\n",
    "    hs_final_sr13 = int(sr13_geo_df_pivot[[jur]].loc[2050].values[0])\n",
    "    hs_final_sr14 = int(sr14_geo_df_pivot[[jur]].loc[2050].values[0])\n",
    "    scheddev_sr13 = int(sr13_sched_dev_totals.loc[ sr13_sched_dev_totals['geo']==jur].iloc[0]['sched_dev_sum'])\n",
    "    scheddev_sr14 = int(sr14_source1.loc[sr14_source1['geo']==jur].iloc[0]['hs_sum'])\n",
    "    total_chg_sr13 = int(sr13_totalchange.loc[jur][0])\n",
    "    total_chg_sr14 = int(sr14_increment.loc[(sr14_increment.increment==2050) & (sr14_increment.geo==jur)].hs_cumulative)\n",
    "    NOT_scheddev_sr13 = total_chg_sr13 - scheddev_sr13\n",
    "    NOT_scheddev_sr14 = total_chg_sr14 - scheddev_sr14\n",
    "\n",
    "    if hs_base_sr13 == 0:\n",
    "        percent_sr13 = str(0) + '%'       \n",
    "    else:\n",
    "        percent_sr13 = str(round(total_chg_sr13/hs_base_sr13 * 100)) + '%'\n",
    "    if hs_base_sr14 == 0:\n",
    "        percent_sr14 = str(0) + '%'         \n",
    "    else:\n",
    "        percent_sr14 = str(round(total_chg_sr14/hs_base_sr14 * 100)) + '%'\n",
    "    if total_chg_sr13 == 0:\n",
    "        percent_chg_sr13_14 = 0\n",
    "    else:\n",
    "        percent_chg_sr13_14 = str(round(total_chg_sr14/total_chg_sr13 * 100)) + '%'\n",
    "    \n",
    "    if total_chg_sr14 != (sum_sch + sum_jur + sum_adu + sum_sgoa):\n",
    "        print(\"Numbers don't match in \"+str(city_cpa_id)+\"!\")\n",
    "        print(\"total_chg_sr14: \"+str(total_chg_sr14))\n",
    "        print(\"scheddev_sr14 + NOT_scheddev_sr14: \"+str(scheddev_sr14 + NOT_scheddev_sr14))\n",
    "        print(\"sum_sch + sum_jur + sum_adu + sum_sgoa: \"+str(sum_sch + sum_jur + sum_adu + sum_sgoa))\n",
    "    \n",
    "    sr13_sr14_hs = pd.DataFrame({'sr13': [hs_base_sr13, hs_final_sr13, total_chg_sr13, (scheddev_sr13 + NOT_scheddev_sr13), \\\n",
    "                                          0, percent_sr13], \\\n",
    "                                 'sr14': [hs_base_sr14, hs_final_sr14, total_chg_sr14, (sum_sch + sum_jur), \\\n",
    "                                          (sum_adu + sum_sgoa), percent_sr14], \\\n",
    "                                 'chg': [(hs_base_sr14 - hs_base_sr13), (hs_final_sr14 - hs_final_sr13), \\\n",
    "                                         (total_chg_sr14 - total_chg_sr13), \\\n",
    "                                         ((sum_sch + sum_jur) - (scheddev_sr13 + NOT_scheddev_sr13)), \\\n",
    "                                         ((sum_adu + sum_sgoa) - 0), percent_chg_sr13_14]},\n",
    "                     index=['Base Year Housing Units (2012/2017)', 'Total Housing Units (2050)', 'Total Change', \\\n",
    "                            '+  Jurisdiction Provided Capacity','+  Additional Capacity', 'Total Percent Change'])\n",
    "    sr13_sr14_hs = sr13_sr14_hs[['sr13', 'sr14', 'chg']]\n",
    "    #print(sr13_sr14_hs)\n",
    "    # sr13_sr14_hs\n",
    "    fig, ax = plt.subplots(figsize=(8, 4)) # set size frame\n",
    "    ax.xaxis.set_visible(False)  # hide the x axis\n",
    "    ax.yaxis.set_visible(False)  # hide the y axis\n",
    "    ax.set_frame_on(False)  # no visible frame, uncomment if size is ok\n",
    "    tabla = table(ax, sr13_sr14_hs, loc='upper right', colWidths=[0.16, 0.16, 0.16])\n",
    "    # colWidths=[0.22]*len(share_count.columns)\n",
    "    tabla.auto_set_font_size(False) # Activate set fontsize manually\n",
    "    tabla.set_fontsize(12) # if ++fontsize is necessary ++colWidths\n",
    "    #tabla.scale(1.2, 1.2) # change size table\n",
    "    tabla.scale(1, 4)\n",
    "    plotname = dirname + '//' + 'city_cpa_' + str(city_cpa_id) + '_' + jur_ + 'forecast_comparison.png'\n",
    "    #plotname = dirname + '//' + str(run_id) + '_city_cpa_' + str(city_cpa_id) + '_' + jur_ + 'percent_capacity_type_table.png'\n",
    "    plt.savefig(plotname, bbox_inches=\"tight\",transparent=True)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
