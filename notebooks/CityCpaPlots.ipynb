{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append path to find utils module in urbansim\n",
    "import os \n",
    "import sys\n",
    "cwd = os.getcwd() \n",
    "parentdir =  os.path.abspath(os.path.join(cwd, os.pardir))\n",
    "sys.path.append(parentdir) # to get path to utils module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, datetime\n",
    "import numpy as np\n",
    "import utils\n",
    "import orca\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import table\n",
    "import matplotlib.patches as mpatches\n",
    "from sqlalchemy import create_engine\n",
    "from database import get_connection_string\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.patches import Rectangle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection_string = get_connection_string('..\\data\\config.yml', 'mssql_db')\n",
    "mssql_engine = create_engine(db_connection_string)\n",
    "versions = utils.yaml_to_dict('../data/scenario_config.yaml', 'scenario')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get subregional simulation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get max run id from urbansim\n",
    "run_id_sql = '''\n",
    "SELECT max(run_id)\n",
    "  FROM [urbansim].[urbansim].[urbansim_lite_output]\n",
    "'''\n",
    "run_id_df = pd.read_sql(run_id_sql, mssql_engine)\n",
    "run_id = int(run_id_df.values)\n",
    "print(\"\\n   Max run id : {:,}\".format(run_id))\n",
    "\n",
    "hs_change_sql = '''\n",
    "    SELECT o.parcel_id, j.name,  p.cap_jurisdiction_id, p.jurisdiction_id, p.mgra_id, p.luz_id,\n",
    "    unit_change as hs_change, source, capacity_type, year_simulation\n",
    "      FROM urbansim.urbansim.urbansim_lite_output o \n",
    "      JOIN urbansim.urbansim.parcel p on p.parcel_id = o.parcel_id\n",
    "      JOIN urbansim.ref.jurisdiction j on p.cap_jurisdiction_id = j.jurisdiction_id\n",
    "     WHERE run_id =  %s\n",
    "  ORDER BY j.name,p.jurisdiction_id, year_simulation'''\n",
    "hs_change_sql = hs_change_sql % run_id\n",
    "hs = pd.read_sql(hs_change_sql,mssql_engine)\n",
    "print(\"\\n   Units added: {:,}\".format(int(hs.hs_change.sum())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### replace sgoa subtypes with 'sgoa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs.replace('cc', 'sgoa',inplace=True)\n",
    "hs.replace('mc', 'sgoa',inplace=True)\n",
    "hs.replace('tc', 'sgoa',inplace=True)\n",
    "hs.replace('tco', 'sgoa',inplace=True)\n",
    "hs.replace('uc', 'sgoa',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap_df = pd.DataFrame({'units_change': hs.groupby(['cap_jurisdiction_id','capacity_type','name']).\\\n",
    "                       hs_change.sum()}).reset_index()\n",
    "\n",
    "cap_summary = cap_df.pivot_table(index=['cap_jurisdiction_id','name'], columns=['capacity_type'], \\\n",
    "                         values=['units_change'])\n",
    "cap_summary.fillna(0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_summary.columns = cap_summary.columns.droplevel(0)\n",
    "cap_summary.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sch','jur','adu','sgoa']\n",
    "cap_summary[cols] = cap_summary[cols].applymap(np.int64)\n",
    "cap_summary['total units'] = cap_summary['sch']  + cap_summary['jur'] + cap_summary['adu'] + cap_summary['sgoa']\n",
    "cap_summary.rename(columns={\"sch\": \"schdev\", \"jur\": \"jur feedback\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_summary.reset_index(inplace=True)\n",
    "# cap_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_summary['jur_provided_total']= cap_summary['schdev'] + cap_summary['jur feedback']\n",
    "cap_summary['additional_capacity_total']= cap_summary['sgoa'] + cap_summary['adu']\n",
    "cap_summary.loc['Total']= cap_summary.sum()\n",
    "cap_summary.loc[cap_summary.index=='Total','name'] = 'Region'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_summary.set_index('cap_jurisdiction_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_summary[['name','schdev','jur feedback','adu','sgoa','total units','jur_provided_total','additional_capacity_total']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QC check output against jurisdiction feedback confluence pg (since all jur capacity used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://sandag.atlassian.net/wiki/spaces/LUM/pages/101679105/Jurisdictional+Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get total dwelling units in the region and sum by jurisdiction and cpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### note using cap jurisdiction id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du_sql = '''\n",
    "    SELECT parcel_id, mgra_id, luz_id, p.jurisdiction_id, cap_jurisdiction_id, j.name, du_2015 as du, du_2017, capacity_2\n",
    "        FROM urbansim.parcel p\n",
    "        LEFT JOIN urbansim.ref.jurisdiction j on p.cap_jurisdiction_id = j.jurisdiction_id'''\n",
    "#        WHERE du_2017 > 0'''\n",
    "du = pd.read_sql(du_sql,mssql_engine)\n",
    "du.cap_jurisdiction_id.fillna(du.jurisdiction_id,inplace=True) # where there is no cap jurisdiction id \n",
    "print(\"\\n   Dwelling Units 2015: {:,}\".format(int(du.du.sum())))\n",
    "print(\"\\n   Dwelling Units 2017: {:,}\".format(int(du.du_2017.sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du_sql = '''\n",
    "    SELECT parcel_id, mgra_id, luz_id, p.jurisdiction_id, cap_jurisdiction_id, j.name, du_2015 as du, du_2017, capacity_2\n",
    "        FROM urbansim.parcel p\n",
    "        LEFT JOIN urbansim.ref.jurisdiction j on p.cap_jurisdiction_id = j.jurisdiction_id\n",
    "        WHERE du_2017 > 0 or du_2015 > 0'''\n",
    "du = pd.read_sql(du_sql,mssql_engine)\n",
    "du.cap_jurisdiction_id.fillna(du.jurisdiction_id,inplace=True) # where there is no cap jurisdiction id \n",
    "print(\"\\n   Dwelling Units 2015: {:,}\".format(int(du.du.sum())))\n",
    "print(\"\\n   Dwelling Units 2017: {:,}\".format(int(du.du_2017.sum())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get CPAs for city and county"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### complete list for plotting even if no housing stock change, i.e. plot zero for those with no change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xref_geography_sql = '''\n",
    "    SELECT mgra_13, cocpa_2016, cicpa_13,cocpa_13, jurisdiction_2016, \n",
    "           COALESCE(cocpa_2016,cicpa_13,cocpa_13) as CPAs\n",
    "      FROM data_cafe.ref.vi_xref_geography_mgra_13'''\n",
    "xref_geography_df = pd.read_sql(xref_geography_sql, mssql_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xref_geography_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get unique CPAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPAs = xref_geography_df.loc[~xref_geography_df.CPAs.isnull()].CPAs.unique().tolist()\n",
    "jurs = xref_geography_df.loc[~xref_geography_df.jurisdiction_2016.isnull()].jurisdiction_2016.unique().tolist()\n",
    "print(len(CPAs))\n",
    "print(len(jurs))\n",
    "Total_city_and_cpa = len(jurs) -2 + len(CPAs)\n",
    "print(Total_city_and_cpa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set \"jcid\" to CPA where jurisdiction id = 14 or 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### simulation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation output\n",
    "units = pd.merge(hs,xref_geography_df,left_on='mgra_id',right_on='mgra_13',how='left')\n",
    "units.loc[units.cap_jurisdiction_id == 19,'jcid'] = units['cocpa_2016']\n",
    "units.loc[units.cap_jurisdiction_id == 14,'jcid'] = units['cicpa_13']\n",
    "units['jcid'].fillna(units['cap_jurisdiction_id'],inplace=True)\n",
    "print(len(units))\n",
    "print(len(hs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dwelling units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dwelling units\n",
    "dus = pd.merge(du,xref_geography_df,left_on='mgra_id',right_on='mgra_13',how = 'left')\n",
    "dus.loc[dus.cap_jurisdiction_id == 19,'jcid'] = dus['cocpa_2016']\n",
    "dus.loc[dus.cap_jurisdiction_id == 14,'jcid'] = dus['cicpa_13']\n",
    "dus['jcid'].fillna(dus['cap_jurisdiction_id'],inplace=True)\n",
    "print(len(dus))\n",
    "print(len(du))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for nulls in jcid or where jcid equal to 14 or 19 instead of a cpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### simulation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(units.loc[units.jcid.isnull()][['parcel_id','jcid','name','cap_jurisdiction_id']])\n",
    "print(units.loc[units.jcid==14][['parcel_id','jcid','name','cap_jurisdiction_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.loc[units.jcid==19][['parcel_id','jcid','name','cap_jurisdiction_id','jurisdiction_id','jurisdiction_2016',\\\n",
    "                           'mgra_id','mgra_13',\\\n",
    "                           'cocpa_2016','cicpa_13','cocpa_13','hs_change']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dwelling units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dus.loc[dus.jcid.isnull()][['parcel_id','jcid','name','cap_jurisdiction_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dus.loc[dus.jcid==14][['parcel_id','jcid','name','cap_jurisdiction_id','jurisdiction_id','jurisdiction_2016',\\\n",
    "                           'mgra_id','mgra_13',\\\n",
    "                           'cocpa_2016','cicpa_13','cocpa_13']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dus.loc[dus.jcid==19][['parcel_id','jcid','name','cap_jurisdiction_id','jurisdiction_id','jurisdiction_2016',\\\n",
    "                           'mgra_id','mgra_13',\\\n",
    "                           'cocpa_2016','cicpa_13','cocpa_13']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually assign CPA to mgra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sql query to find nearest CPA if necessary"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SELECT MGRA, City, CPA, Shape \n",
    "FROM [spacecore].[ref].[mgra13] as p1 \n",
    "WHERE p1.shape.STWithin((SELECT shape FROM [spacecore].[ref].[mgra13] where MGRA = 19415).STBuffer(5000)) = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### simulation output CPA 1909 to mgra 19415 & 18831"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.loc[units.mgra_id==19415,'jcid'] = 1909\n",
    "units.loc[units.mgra_id==18831,'jcid'] = 1909"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dwelling units CPA 1909 to mgra 19415 & 18831, jur 13 to mgra 11514 & jur 3 to mgra 7521"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually assign CPA or jurisdiction to mgra 19415,11514,18831\n",
    "dus.loc[dus.mgra_id==19415,'jcid'] = 1909\n",
    "dus.loc[dus.mgra_id==18831,'jcid'] = 1909\n",
    "dus.loc[dus.mgra_id==11514.0,'jcid'] = 13\n",
    "dus.loc[dus.mgra_id==7521.0,'jcid'] = 3\n",
    "# dus.loc[dus.mgra_13==7259,'jcid'] = 1439 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Add CPAs where there was no unit change or dwelling units to complete dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### simulation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.jcid = units.jcid.astype(int)\n",
    "units.parcel_id = units.parcel_id.astype(int)\n",
    "units.set_index('jcid',inplace=True) # necessary for adding missing CPAs\n",
    "jcids = units.index.unique().tolist()\n",
    "CPAs_no_unit_change = np.setdiff1d(CPAs,jcids).tolist()\n",
    "CPAs_no_unit_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need jcid as index here\n",
    "for cpa in CPAs_no_unit_change:\n",
    "    units.loc[cpa] = np.nan\n",
    "units.reset_index(inplace=True) # reset index after assigning CPAs\n",
    "units.fillna(0,inplace=True)\n",
    "len(units.jcid.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set simulation year to '2017' for CPAs that had no housing unit change to complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set year to 2017 for 9 CPAs with no data\n",
    "units.loc[units.year_simulation==0,'year_simulation'] = 2017\n",
    "units.year_simulation = units.year_simulation.astype(int)\n",
    "units.loc[units.jcid.isin(CPAs_no_unit_change)][['parcel_id','jcid','cap_jurisdiction_id','hs_change',\\\n",
    "                          'year_simulation']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dwelling units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dus.jcid = dus.jcid.astype(int)\n",
    "dus.parcel_id = dus.parcel_id.astype(int)\n",
    "dus.set_index('jcid',inplace=True) # necessary for adding missing CPAs\n",
    "jcids = dus.index.unique().tolist()\n",
    "CPAs_no_unit_change = np.setdiff1d(CPAs,jcids).tolist()\n",
    "CPAs_no_unit_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need jcid as index here\n",
    "for cpa in CPAs_no_unit_change:\n",
    "    dus.loc[cpa] = np.nan\n",
    "dus.reset_index(inplace=True) # reset index after assigning CPAs\n",
    "dus.fillna(0,inplace=True)\n",
    "len(dus.jcid.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add cpa name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cocpa_names_sql = '''\n",
    "    SELECT zone as cocpa_id, name as cocpa\n",
    "    FROM data_cafe.ref.geography_zone WHERE geography_type_id = 20'''\n",
    "cocpa_names = pd.read_sql(cocpa_names_sql, mssql_engine)\n",
    "cicpa_names_sql = '''\n",
    "    SELECT zone as cicpa_id, name as cicpa\n",
    "    FROM data_cafe.ref.geography_zone WHERE geography_type_id = 15'''\n",
    "cicpa_names = pd.read_sql(cicpa_names_sql, mssql_engine)\n",
    "luz_names_sql = '''\n",
    "    SELECT zone as luz_id, name as luz\n",
    "    FROM data_cafe.ref.geography_zone WHERE geography_type_id = 64'''\n",
    "luz_names = pd.read_sql(luz_names_sql, mssql_engine)    \n",
    "jurisdictions_names_sql = '''\n",
    "    SELECT zone as jurisdiction_id_data_cafe, name as jurisdiction\n",
    "    FROM data_cafe.ref.geography_zone WHERE geography_type_id = 150'''\n",
    "jur_name_df = pd.read_sql(jurisdictions_names_sql, mssql_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = pd.merge(units,cocpa_names,left_on='jcid',right_on='cocpa_id',how = 'left')\n",
    "units = pd.merge(units,cicpa_names,left_on='jcid',right_on='cicpa_id',how = 'left')\n",
    "units = pd.merge(units,jur_name_df,left_on='jurisdiction_2016',right_on='jurisdiction_id_data_cafe',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units['jcname'] = units['name']\n",
    "units.loc[units.jcid>=1900,'jcname'] = units['cocpa']\n",
    "units.loc[(units.jcid>=1400) & (units.jcid<1900),'jcname'] = units['cicpa']\n",
    "units.loc[units.jcname==0,'jcname'] = units['jurisdiction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that there are no nulls values (should equal 103)\n",
    "len(units.jcname.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check results again to match jurisdiction feedback page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_df = pd.DataFrame({'chg': units.groupby(['jcid','jcname']).\n",
    "                               hs_change.sum()}).reset_index()\n",
    "change_df['jcid'] =change_df['jcid'].astype(int)\n",
    "change_df.set_index('jcid',inplace=True)\n",
    "# change_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get SR13 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sql = '''\n",
    "select x.mgra, sum([hs]) AS hs, increment, city, cpa, x.luz as luz_id,site\n",
    "from [regional_forecast].[sr13_final].[capacity] x\n",
    "join [regional_forecast].[sr13_final].[mgra13] y\n",
    "on x.mgra = y.mgra\n",
    "where scenario = 0 \n",
    "group by x.mgra, site, increment, y.city,y.cpa,x.luz\n",
    "order by x.mgra, increment'''\n",
    "sr13_df = pd.read_sql(sr13_sql, mssql_engine)\n",
    "# count results\n",
    "nmgra = int(len(sr13_df.mgra.unique()))\n",
    "nincrements = int(len(sr13_df.increment.unique()))\n",
    "lendf = int(len(sr13_df))\n",
    "duplicated_df = sr13_df[sr13_df.duplicated(subset=['mgra','increment'], keep=\"first\")]\n",
    "numdup = int(len(duplicated_df))\n",
    "mi = nmgra*nincrements\n",
    "nodups = lendf - numdup\n",
    "print(\"\\n   Number of increments: {:,}\".format(nincrements))\n",
    "print(\"\\n   Number of mgras: {:,}\".format(nmgra))\n",
    "print(\"\\n        increments * mgras: {:,}\".format(mi))\n",
    "print(\"\\nsr13 dataframe length: {:,}\".format(lendf))\n",
    "print(\"\\n   Number of duplicates: {:,}  (mgra w site id and not site id)\".format(numdup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get CPAs for city and county for sr13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_df = pd.merge(sr13_df,jur_name_df[['jurisdiction_id_data_cafe','jurisdiction']],left_on='city',\\\n",
    "                   right_on='jurisdiction_id_data_cafe')\n",
    "sr13_df = pd.merge(sr13_df,cocpa_names[['cocpa_id','cocpa']],left_on='cpa',right_on='cocpa_id', how = 'outer')\n",
    "sr13_df = pd.merge(sr13_df,cicpa_names[['cicpa_id','cicpa']],left_on='cpa',right_on='cicpa_id',how = 'outer')\n",
    "sr13_df = pd.merge(sr13_df,luz_names[['luz_id','luz']],left_on='luz_id',right_on='luz_id')\n",
    "sr13_df['jur_or_cpa_name'] = sr13_df['cocpa']\n",
    "sr13_df['jur_or_cpa_name'].fillna(sr13_df['cicpa'],inplace=True)\n",
    "sr13_df['jur_or_cpa_name'].fillna(sr13_df['jurisdiction'],inplace=True)\n",
    "sr13_df['jur_or_cpa_id'] = sr13_df['cocpa_id']\n",
    "sr13_df['jur_or_cpa_id'].fillna(sr13_df['cicpa_id'],inplace=True)\n",
    "sr13_df['jur_or_cpa_id'].fillna(sr13_df['jurisdiction_id_data_cafe'],inplace=True)\n",
    "sr13_df['jur_or_cpa_id'] = sr13_df['jur_or_cpa_id'].astype(int)\n",
    "sr13_df.drop(['jurisdiction_id_data_cafe', 'cocpa_id', 'cicpa_id', 'cocpa', 'cicpa'], axis=1,inplace=True)\n",
    "# sr13_df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sr13_df['jur_or_cpa_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sum dwelling units by jursidictions and CPAs (n=103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du_sr14_geo_df = dus.groupby(['jcid'])[[\"du\",\"du_2017\"]].sum()\n",
    "du_sr14_geo_df['du_2017'] = du_sr14_geo_df['du_2017'].astype(int)\n",
    "du_sr14_geo_df['du'] = du_sr14_geo_df['du'].astype(int)\n",
    "print(\"\\n Total residential dwelling units 2015: {:,}\".format(int(du_sr14_geo_df.du.sum())))\n",
    "print(\"\\n Total residential dwelling units 2017: {:,}\".format(int(du_sr14_geo_df.du_2017.sum())))\n",
    "print(\"\\n Total number of jurisdictions and cpas: {:,}\\n\".format(len(du_sr14_geo_df.index.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du_sr14_geo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sum hs change in simulation by jursidictions and CPAs (n=103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_geo_df = pd.DataFrame({'hs_sum': units.groupby(['jcid','jcname','year_simulation']).\\\n",
    "                            hs_change.sum()}).reset_index()\n",
    "sr14_geo_df.rename(columns = {'jcname':'geo'},inplace=True)\n",
    "# sr14_geo_df.rename(columns = {'year_simulation':'increment'},inplace=True)\n",
    "sr14_geo_df.sort_values(by='jcid',inplace=True)\n",
    "sr14_geo_df.set_index('jcid',inplace=True)\n",
    "sr14_geo_df['hs_sum'] = sr14_geo_df['hs_sum'].astype(int)\n",
    "sr14_geo_df['year_simulation'] = sr14_geo_df['year_simulation'].astype(int)\n",
    "print(\"\\n Total housing unit change after groupby: {:,}\".format(int(sr14_geo_df.hs_sum.sum())))\n",
    "print(\"\\n Total number of jurisdictions and cpas: {:,}\\n\".format(len(sr14_geo_df.index.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_geo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sched dev totals - sum simulation output by source (fill NA with \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_source = pd.DataFrame({'hs_sum': units.groupby(['source','jcid','jcname']).\\\n",
    "                            hs_change.sum()}).reset_index()\n",
    "sr14_source.rename(columns = {'jcname':'geo'},inplace=True)\n",
    "sr14_source.sort_values(by='jcid',inplace=True)\n",
    "sr14_source.set_index('jcid',inplace=True)\n",
    "sr14_source['hs_sum'] = sr14_source['hs_sum'].astype(int)\n",
    "print(\"\\n Total housing unit change after groupby: {:,}\".format(int(sr14_source.hs_sum.sum())))\n",
    "print(\"\\n Total number of jurisdictions and cpas: {:,}\\n\".format(len(sr14_source.index.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = range(1,4)\n",
    "sr14_source.set_index(['geo','source'],append=True,inplace=True)\n",
    "sr14_source = sr14_source.unstack(['jcid','geo'])\n",
    "# sr14_source = sr14_source.reindex(idx, fill_value=0)\n",
    "sr14_source.fillna(0,inplace=True)\n",
    "sr14_source = sr14_source.stack(['jcid','geo'])\n",
    "sr14_source.reset_index(inplace=True)\n",
    "sr14_source.set_index('jcid',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sched dev totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_source1 =  sr14_source.loc[sr14_source.source==1.0].copy()\n",
    "sr14_source1.head(5)\n",
    "print(sr14_source1.hs_sum.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get SR13 sched dev totals by jur and cpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev_sql = '''\n",
    "SELECT x.mgra,city, cpa, x.luz as luz_id,site, sum(siteSF+siteMF+siteMH) AS sched_dev\n",
    "FROM [regional_forecast].[sr13_final].[capacity] x\n",
    "join [regional_forecast].[sr13_final].[mgra13] y\n",
    "on x.mgra = y.mgra\n",
    "where scenario = 0 and increment = 2050 and site != 0 and (siteSF + siteMF + siteMH) > 0 \n",
    "group by x.mgra, site, increment, y.city,y.cpa,x.luz\n",
    "order by city,site'''\n",
    "sr13_sched_dev = pd.read_sql(sr13_sched_dev_sql, mssql_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev.sched_dev.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev = pd.merge(sr13_sched_dev,jur_name_df[['jurisdiction_id_data_cafe','jurisdiction']],\\\n",
    "                          left_on='city',right_on='jurisdiction_id_data_cafe',how='outer')\n",
    "sr13_sched_dev = pd.merge(sr13_sched_dev,cocpa_names[['cocpa_id','cocpa']],left_on='cpa',right_on='cocpa_id', how = 'outer')\n",
    "sr13_sched_dev = pd.merge(sr13_sched_dev,cicpa_names[['cicpa_id','cicpa']],left_on='cpa',right_on='cicpa_id',how = 'outer')\n",
    "# sr13_sched_dev = pd.merge(sr13_sched_dev,luz_names[['luz_id','luz']],left_on='luz_id',right_on='luz_id',how='outer')\n",
    "sr13_sched_dev['jur_or_cpa_name'] = sr13_sched_dev['cocpa']\n",
    "sr13_sched_dev['jur_or_cpa_name'].fillna(sr13_sched_dev['cicpa'],inplace=True)\n",
    "sr13_sched_dev['jur_or_cpa_name'].fillna(sr13_sched_dev['jurisdiction'],inplace=True)\n",
    "sr13_sched_dev['jur_or_cpa_id'] = sr13_sched_dev['cocpa_id']\n",
    "sr13_sched_dev['jur_or_cpa_id'].fillna(sr13_sched_dev['cicpa_id'],inplace=True)\n",
    "sr13_sched_dev['jur_or_cpa_id'].fillna(sr13_sched_dev['jurisdiction_id_data_cafe'],inplace=True)\n",
    "# sr13_sched_dev['jur_or_cpa_id'] = sr13_sched_dev['jur_or_cpa_id'].astype(int)\n",
    "sr13_sched_dev.drop(['jurisdiction_id_data_cafe', 'cocpa_id', 'cicpa_id', 'cocpa', 'cicpa'], axis=1,inplace=True)\n",
    "sr13_sched_dev.rename(columns = {'jur_or_cpa_name':'geo'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev.loc[sr13_sched_dev.jur_or_cpa_id ==8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev.loc[sr13_sched_dev.jur_or_cpa_id.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev['jur_or_cpa_id'] = sr13_sched_dev['jur_or_cpa_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev_totals = pd.DataFrame({'sched_dev_sum': sr13_sched_dev.\n",
    "                                            groupby([\"jur_or_cpa_id\",'geo']).\n",
    "                                 sched_dev.sum()}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev_totals.sched_dev_sum.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_sched_dev_totals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in \"0\" for units for \"missing\" simulation years (for plotting) (e.g. Del Mar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Del Mar example\n",
    "del_mar_before = sr14_geo_df.loc[4].sort_values(by='year_simulation')\n",
    "# del_mar_before.head()\n",
    "del_mar_before.plot(x='year_simulation',y='hs_sum',style='.-',title='NULL values in Del Mar Housing Unit Change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del_mar_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = range(2017,2051)\n",
    "sr14_geo_df.set_index(['geo','year_simulation'],append=True,inplace=True)\n",
    "sr14_geo_df = sr14_geo_df.unstack(['jcid','geo'])\n",
    "sr14_geo_df = sr14_geo_df.reindex(idx, fill_value=0)\n",
    "sr14_geo_df.fillna(0,inplace=True)\n",
    "sr14_geo_df = sr14_geo_df.stack(['jcid','geo'])\n",
    "sr14_geo_df.reset_index(inplace=True)\n",
    "sr14_geo_df.set_index('jcid',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_mar_after = sr14_geo_df.loc[4].sort_values(by='year_simulation')\n",
    "del_mar_after.plot(x='year_simulation',y='hs_sum',style='.-',title='Replace Null with Zeroes Del Mar Housing Unit Change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sr14_geo_df.geo.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(du_sr14_geo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sr14_geo_df.year_simulation.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sr14_geo_df.year_simulation.unique()) * len(sr14_geo_df.geo.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sr14_geo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_geo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum units from output of simulation over five year increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = range(2015,2055,5)\n",
    "names = [str(x) for x in range(2020,2055,5)]\n",
    "sr14_geo_df['increment'] = pd.cut(sr14_geo_df.year_simulation, bins, labels=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_increment = pd.DataFrame({'hs_increment': sr14_geo_df.\n",
    "                                            groupby([\"increment\",\"jcid\",\"geo\"]).\n",
    "                                 hs_sum.sum()}).reset_index()\n",
    "# sr14_increment.set_index('jcid',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_increment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_increment.increment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_increment.increment = sr14_increment.increment.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative sum units added by increment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_increment['hs_cumulative'] = sr14_increment.groupby(['geo'])['hs_increment'].apply(lambda x: x.cumsum())\n",
    "sr14_increment.set_index('jcid',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_increment.loc[sr14_increment.geo=='Carlsbad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join simulation output with existing dwelling units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sr14_increment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(du_sr14_geo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14 = sr14_increment.join(du_sr14_geo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14['hs'] = sr14['hs_cumulative'] + sr14['du_2017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sr14.loc[1].sort_values(by='increment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2050 = sr14.loc[sr14.increment==2050].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2050.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2050['Housing Units 2050'] = results2050['hs'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2050['Housing Units 2017'] = results2050['du_2017'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2050['Housing Units Change'] = results2050['hs_cumulative'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2050['Name'] = results2050['geo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2050['id'] = results2050.index\n",
    "results2050['City'] = results2050.Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2050.loc[results2050.index.isin(range(1399,1501)),'id'] = 14\n",
    "results2050.loc[results2050.index.isin(range(1899,2001)),'id'] = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2050.loc[results2050.index.isin(range(1399,1501)),'City'] = 'San Diego'\n",
    "results2050.loc[results2050.index.isin(range(1899,2001)),'City'] = 'Unincorporated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "juroutput_chg = pd.DataFrame({'Total Unit Change':  results2050.groupby(['id','City']).\\\n",
    "                          hs_cumulative.sum()}).reset_index()\n",
    "juroutput_chg.set_index('id',inplace=True)\n",
    "juroutput_chg['Total Unit Change'] = juroutput_chg['Total Unit Change'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "juroutput_chg3 = pd.DataFrame({'Units 2050':  results2050.groupby(['id','City']).\\\n",
    "                          hs.sum()}).reset_index()\n",
    "juroutput_chg3.set_index('id',inplace=True)\n",
    "juroutput_chg3['Units 2050'] = juroutput_chg3['Units 2050'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "juroutput_chg2 = pd.DataFrame({'Units 2017':  results2050.groupby(['id','City']).\\\n",
    "                          du_2017.sum()}).reset_index()\n",
    "juroutput_chg2.set_index('id',inplace=True)\n",
    "\n",
    "juroutput_chg2['Units 2050'] = juroutput_chg3['Units 2050']\n",
    "juroutput_chg2['Total Unit Change'] = juroutput_chg['Total Unit Change']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "juroutput_chg2.loc['Total']= juroutput_chg2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "juroutput_chg2.loc[juroutput_chg2.index=='Total','City'] = 'Region'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# juroutput_chg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sr13_df = pd.DataFrame({'hs_sum': sr13_df.groupby(['city','jurisdiction','increment']).\n",
    "                               hs.sum()}).reset_index()\n",
    "\n",
    "output_sr13_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2050 = sr14.loc[sr14.increment==2050].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output2050 = results2050[['Name','Housing Units 2017','Housing Units 2050','Housing Units Change']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output2050.loc['Total']= output2050.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output2050.loc[output2050.index=='Total','Name'] = 'Region'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output2050['jur'] = output2050.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# juroutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output2050.loc[output2050.index.isin(range(1399,1501))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output2050.loc[output2050.index.isin(range(0,19))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add increment 2016 with units added equal to zero for baseline du (for plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = sr14_geo_df.loc[sr14_geo_df.year_simulation==2017].copy()\n",
    "len(start_year)\n",
    "start_year['increment'] = 2015\n",
    "start_year = start_year.join(du_sr14_geo_df)\n",
    "start_year['hs'] = start_year['du']\n",
    "start_year['year_simulation'] = 'baseline'\n",
    "sr14 = pd.concat([sr14,start_year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year['increment'] = 2017\n",
    "start_year['hs'] = start_year['du_2017']\n",
    "sr14 = pd.concat([sr14,start_year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sr14.loc[1420].sort_values(by='increment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SR13 aggregrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  mgra level housing to cpa and jurisdiction and group by increment and sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_geo_df = pd.DataFrame({'hs_sum': sr13_df.groupby(['jur_or_cpa_name','jur_or_cpa_id','increment']).\n",
    "                               hs.sum()}).reset_index()\n",
    "sr13_geo_df.rename(columns = {'jur_or_cpa_name':'geo'},inplace=True)\n",
    "sr13_geo_df.sort_values(by='jur_or_cpa_id',inplace=True)\n",
    "sr13_geo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNum of geographies (jurisdiction plus cpa) = {:,}\\n\".format(int(len(sr13_geo_df.loc[sr13_geo_df.increment==2015]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_geo_df.loc[sr13_geo_df.geo=='Escondido'].sort_values(by='increment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  sr13 pivot so each jurisdiction or cpa is column and rows are increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_geo_df_pivot = sr13_geo_df.pivot\\\n",
    "(index='increment', columns='geo', values='hs_sum').\\\n",
    "reset_index().rename_axis(None, axis=1)\n",
    "sr13_geo_df_pivot.set_index('increment',inplace=True)\n",
    "sr13_geo_df_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  sr14 pivot so each jurisdiction or cpa is column and rows are increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_geo_df_pivot = sr14.pivot\\\n",
    "(index='increment', columns='geo', values='hs').\\\n",
    "reset_index().rename_axis(None, axis=1)\n",
    "sr14_geo_df_pivot.set_index('increment',inplace=True)\n",
    "sr14_geo_df_pivot.fillna(0,inplace=True)\n",
    "sr14_geo_df_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  sr13 calculate total change by region and jurisdiction and cpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_diff = sr13_geo_df_pivot.loc[[2012,2050],:]\n",
    "differences = total_diff.diff().loc[[2050]]\n",
    "differences.rename(index={2050: 'total_change'},inplace=True)\n",
    "totalchange = pd.DataFrame(differences.sum(axis=0))\n",
    "totalchange.rename(columns={0: 'total_change'},inplace=True)\n",
    "sr13_totalchange = pd.DataFrame(differences.sum(axis=0))\n",
    "sr13_totalchange.rename(columns={0: 'total_change'},inplace=True)\n",
    "print(\"\\nTotal Units added sr13: {:,}\".format(int(totalchange.total_change.sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolist = sr14_geo_df.geo.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for jur in (geolist):\n",
    "    s = str(jur)\n",
    "    l.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print '[%s]' % ', '.join(map(str, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolist[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jur = geolist[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheddevlabel_sr13 = '(' + str(int( sr13_sched_dev_totals.loc[ sr13_sched_dev_totals['geo']==jur].iloc[0]['sched_dev_sum'])) + ' sched dev)'    \n",
    "scheddevlabel_sr13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### directory for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = os.path.join(os.getcwd(),'plots')#,datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "                       \n",
    "                       # 'run_'+str(run_id) + '_city_cpa')\n",
    "                         \n",
    "try:\n",
    "    os.stat(dirname)\n",
    "except:\n",
    "    os.mkdir(dirname)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print dirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sr13_geo_df_pivot.columns.tolist()\n",
    "# sr13_geo_df_pivot[[jur]]\n",
    "# sr14_geo_df_pivot[[jur]]\n",
    "len(sr14_geo_df_pivot.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_geo_df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sr14_geo_df_pivot.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheddevlabel_sr13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '(' + str(int( sr13_sched_dev_totals.loc[ sr13_sched_dev_totals['geo']==jur].iloc[0]['sched_dev_sum'])) + ' sched dev)'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_geo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolist[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot figures as png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COPY\n",
    "for j, jur in enumerate(geolist):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        chg = int(sr14_increment.loc[(sr14_increment.increment==2050) & (sr14_increment.geo==jur)].hs_cumulative)\n",
    "        plotlabelsr13 = 'sr13 '\n",
    "        plotlabelsr14 = 'sr14 '\n",
    "        scheddevlabel_sr13 = '(' + str(int( sr13_sched_dev_totals.loc[ sr13_sched_dev_totals['geo']==jur].iloc[0]['sched_dev_sum'])) + ' sched dev)'    \n",
    "        scheddevlabel = '(' + str(int(sr14_source1.loc[sr14_source1['geo']==jur].iloc[0]['hs_sum'])) + ' sched dev)'\n",
    "        sr14_increments_int = sr14_geo_df_pivot[[jur]].reset_index().increment.tolist()\n",
    "        sr13_increments_int = sr13_geo_df_pivot[[jur]].reset_index().increment.tolist()\n",
    "        \n",
    "        \n",
    "        sr14 = ax.plot(sr14_increments_int,\n",
    "                       sr14_geo_df_pivot[[jur]].reset_index()[jur].tolist(),'b-o')\n",
    "        sr13 = plt.plot(sr13_increments_int,\n",
    "                        sr13_geo_df_pivot[[jur]].reset_index()[jur].tolist(),'r-o')\n",
    "          \n",
    "        city_cpa_id = str(sr14_geo_df.loc[sr14_geo_df['geo']==jur].index.values[0])  \n",
    "       \n",
    "        # legendtitle = jur + ' (' +  city_cpa_id + ')'\n",
    "\n",
    "                \n",
    "        # create blank rectangle\n",
    "        extra = Rectangle((0, 0), 1, 1, fc=\"w\", fill=False, edgecolor='none', linewidth=0)\n",
    "        ax.legend([sr14[0],sr13[0]],\\\n",
    "                  (plotlabelsr14,plotlabelsr13))\n",
    "        # extra2 = Rectangle((0, 0), 1, 1, fc=\"w\", fill=False, edgecolor='none', linewidth=0)\n",
    "        # extra3 = Rectangle((0, 0), 1, 1, fc=\"w\", fill=False, edgecolor='none', linewidth=0)\n",
    "        # ax.legend([extra, sr13[0],extra2,sr14[0],extra3], (\"Total Chg\", plotlabelsr13,scheddevlabel_sr13, plotlabelsr14,scheddevlabel))\n",
    "        # plt.ylabel('Housing stock')\n",
    "        # plt.xlabel('Year')\n",
    "        # plt.title('Series 13 and DRAFT Series 14 Comparison\\n' + jur + ' (id=' +  city_cpa_id + ')')\n",
    "        ptitle = 'DRAFT Series 14 and Series 13 Comparison\\n' + jur + ' (id=' +  str(city_cpa_id) + ')'\n",
    "        ax.set_title(ptitle,fontsize= 14)\n",
    "        ax.set_xlabel(\"Year\",size=14)\n",
    "        ax.set_ylabel(\"Housing stock\",size=14)\n",
    "        # ptitle = 'DRAFT Cumulative Housing Units Added By Capacity Type\\n' + jur + ' (id=' +  str(city_cpa_id) + ')'\n",
    "        jur_ = jur.replace(\":\", \"_\") # colon not allowed in windows filename\n",
    "        plotname = 'plots' + '//' + str(run_id) + '_city_cpa_' + city_cpa_id + '_' + jur_ + '.png'\n",
    "        # plotname = dirname + '//' + str(run_id) + '_city_cpa_' + city_cpa_id + '_' + jur_ + '.png'\n",
    "\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(6, 4.5)\n",
    "        fig.savefig(plotname, bbox_inches='tight',dpi=200)\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "        \n",
    "        \n",
    "        # ptitle = 'DRAFT Cumulative Housing Units Added By Capacity Type\\n' + jur + ' (id=' +  str(city_cpa_id) + ')'\n",
    "        # ax.set_ylabel(\"housing units added\",size=14)\n",
    "        # ax.set_title(ptitle,size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for j, jur in enumerate(geolist):\n",
    "    if jur == 'blank':\n",
    "        img = np.zeros([100,100,3],dtype=np.uint8)\n",
    "        img.fill(255)\n",
    "        # plotname = 'out/luz4/' + str(j+1) + '_luz.png'\n",
    "        # imsave( plotname,img)\n",
    "    else:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        \n",
    "        chg = int(sr14_increment.loc[(sr14_increment.increment==2050) & (sr14_increment.geo==jur)].hs_cumulative)\n",
    "        \n",
    "        plotlabelsr13 = 'sr13: ' +  ' ' + str(int(totalchange.loc[jur][0]))\n",
    "        \n",
    "        plotlabelsr14 = 'sr14: '+ ' ' + str(chg)  # + '\\n(sched dev = ' + \\\n",
    "              # str(int(sr14_source1.loc[sr14_source1['geo']==jur].iloc[0]['hs_sum'])) + ')'\n",
    "            \n",
    "        scheddevlabel_sr13 = '(' + str(int( sr13_sched_dev_totals.loc[ sr13_sched_dev_totals['geo']==jur].iloc[0]['sched_dev_sum'])) + ' sched dev)'    \n",
    "        scheddevlabel = '(' + str(int(sr14_source1.loc[sr14_source1['geo']==jur].iloc[0]['hs_sum'])) + ' sched dev)'\n",
    "        \n",
    "        sr14_increments_int = sr14_geo_df_pivot[[jur]].reset_index().increment.tolist()\n",
    "        \n",
    "        \n",
    "        sr14 = ax.plot(sr14_increments_int,\n",
    "                       sr14_geo_df_pivot[[jur]].reset_index()[jur].tolist(),'b-o', label=plotlabelsr14)\n",
    "    \n",
    "        sr13_increments_int = sr13_geo_df_pivot[[jur]].reset_index().increment.tolist()\n",
    "        \n",
    "    \n",
    "        sr13 = plt.plot(sr13_increments_int,\n",
    "                        sr13_geo_df_pivot[[jur]].reset_index()[jur].tolist(),'r-o', label=plotlabelsr13)\n",
    "          \n",
    "        city_cpa_id = str(sr14_geo_df.loc[sr14_geo_df['geo']==jur].index.values[0])    \n",
    "        legendtitle = jur + ' (' +  city_cpa_id + ')'\n",
    "\n",
    "                \n",
    "        # create blank rectangle\n",
    "        extra = Rectangle((0, 0), 1, 1, fc=\"w\", fill=False, edgecolor='none', linewidth=0)\n",
    "        extra2 = Rectangle((0, 0), 1, 1, fc=\"w\", fill=False, edgecolor='none', linewidth=0)\n",
    "        extra3 = Rectangle((0, 0), 1, 1, fc=\"w\", fill=False, edgecolor='none', linewidth=0)\n",
    "        ax.legend([extra, sr13[0],extra2,sr14[0],extra3], (\"Total Chg\", plotlabelsr13,scheddevlabel_sr13, plotlabelsr14,scheddevlabel))\n",
    "        plt.ylabel('Housing stock')\n",
    "        plt.xlabel('Increment')\n",
    "        plt.title('Series 13 and DRAFT Series 14 Comparison\\n' + legendtitle)\n",
    "        jur_ = jur.replace(\":\", \"_\") # colon not allowed in windows filename\n",
    "        plotname = dirname + '//' + str(run_id) + '_city_cpa_' + city_cpa_id + '_' + jur_ + '.png'\n",
    "        \n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(6, 4.5)\n",
    "        fig.savefig(plotname, bbox_inches='tight',dpi=200)\n",
    "        #plt.show()\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  AS PDF instead of png"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# pp = PdfPages(\"out/sr13_and_draft_sr14_compare_3_w_2controlsb.pdf\")# \n",
    "# pdfdirname = os.path.join(os.getcwd(),'plots') ,datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "# pdfplotname = pdfdirname + '//' + str(run_id) + '_city_cpa_' + str(j+1) + '_' +\\\n",
    "#              datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')) + '.pdf'\n",
    "# pp = PdfPages(pdfplotname)\n",
    "\n",
    "\n",
    "# for j, jur in enumerate(sr14_geo_df.geo.unique().tolist()):\n",
    "# for j, jur in  enumerate(['Carlsbad','Chula Vista']):\n",
    "#    chg = int(sr14_increment.loc[(sr14_increment.increment=='2050') & (sr14_increment.geo==jur)].hs_cumulative)\n",
    "#    jur_and_cpa_plot = plt.figure()\n",
    "    # plt.subplot(20, 1, j+1)\n",
    "    # plotlabel = jur + '\\nchg = ' + str(int(totalchange.loc[jur][0]))\n",
    "#    plotlabelsr14 = 'sr14: '+ str(sr14_geo_df.loc[sr14_geo_df['geo']==jur].index.values[0]) + '.' +\\\n",
    "#                jur + '\\nchg = ' + str(chg) + '\\n(sched dev = ' + \\\n",
    "#                str(int(sr14_source1.loc[sr14_source1['geo']==jur].iloc[0]['hs_sum'])) + ')'\n",
    "#    plotlabelsr13 = 'sr13: ' + str(sr13_geo_df.loc[sr13_geo_df['geo']==jur].jur_or_cpa_id.values[0]) + '.' +\\\n",
    "#                jur + '\\nchg = ' + str(int(totalchange.loc[jur][0]))\n",
    "    \n",
    "    #plt.plot(sr14_geo_df_pivot[[jur]].reset_index().increment.tolist(),sr14_geo_df_pivot[[jur]].reset_index()[jur].tolist(),\n",
    "            # label=plotlabelsr14,\n",
    "    #         sr13_geo_df_pivot[[jur]].reset_index().increment.tolist(),sr13_geo_df_pivot[[jur]].reset_index()[jur].tolist(),\n",
    "     #        label=plotlabelsr13\n",
    "     #       )\n",
    "#    plt.plot(sr14_geo_df_pivot[[jur]].reset_index().increment.tolist(),\n",
    "#             sr14_geo_df_pivot[[jur]].reset_index()[jur].tolist(),'b-o', label=plotlabelsr14)\n",
    "#    plt.plot(sr13_geo_df_pivot[[jur]].reset_index().increment.tolist(),\n",
    "#             sr13_geo_df_pivot[[jur]].reset_index()[jur].tolist(),'r-o', label=plotlabelsr13)\n",
    "#    plt.legend()\n",
    "#    plt.ylabel('Housing stock')\n",
    "#    plt.xlabel('Increment')\n",
    "#    plt.title('Series 13 and Draft Series 14\\n   at Jurisdiction and CPA')\n",
    "#    pp.savefig(jur_and_cpa_plot, dpi = 300, transparent = True)\n",
    "# pp.close()\n",
    "# plt.savefig('sr13_jur_and_cpa.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "units_added_by_source.plot(style='.-',stacked=True,kind='bar',ax=axes.flat[2],\\\n",
    "                           figsize=(10,15),color=['red','purple','green','sandybrown'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# QC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "units[['jcid','name','parcel_id','hs_change','source','year_simulation']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j1414 = units[['jcid','name','parcel_id','hs_change','source','year_simulation']].loc[units.jcid==1414]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j1414.sort_values(by='year_simulation',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j1414.hs_change.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j1414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### COPY\n",
    "for j, jur in enumerate(geolist):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        chg = int(sr14_increment.loc[(sr14_increment.increment==2050) & (sr14_increment.geo==jur)].hs_cumulative)\n",
    "        plotlabelsr13 = 'sr13 '\n",
    "        plotlabelsr14 = 'sr14 '\n",
    "        sr14 = ax.plot(sr14_increments_int,\n",
    "        sr14_geo_df_pivot[[jur]].reset_index()[jur].tolist(),'b-o')\n",
    "        sr13 = plt.plot(sr13_increments_int,\n",
    "                        sr13_geo_df_pivot[[jur]].reset_index()[jur].tolist(),'r-o')\n",
    "        city_cpa_id = str(sr14_geo_df.loc[sr14_geo_df['geo']==jur].index.values[0])  \n",
    "        ax.legend([sr14[0],sr13[0]],(plotlabelsr14,plotlabelsr13))\n",
    "        ptitle = 'DRAFT Series 14 and Series 13 Comparison\\n' + jur + ' (id=' +  str(city_cpa_id) + ')'\n",
    "        ax.set_title(ptitle,fontsize= 14)\n",
    "        ax.set_xlabel(\"Year\",size=14)\n",
    "        ax.set_ylabel(\"Housing stock\",size=14)\n",
    "        jur_ = jur.replace(\":\", \"_\") # colon not allowed in windows filename\n",
    "        plotname = 'plots/test3' + '//' + str(run_id) + '_city_cpa_' + city_cpa_id + '_' + jur_ + '.png'\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(6, 4.5)\n",
    "        fig.savefig(plotname, bbox_inches='tight',dpi=200)\n",
    "        plt.show()\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get max run id from urbansim\n",
    "run_id_sql = '''\n",
    "SELECT max(run_id)\n",
    "  FROM [urbansim].[urbansim].[urbansim_lite_output]\n",
    "'''\n",
    "run_id_df = pd.read_sql(run_id_sql, mssql_engine)\n",
    "run_id = int(run_id_df.values)\n",
    "print(\"\\nRun id : {:,}\".format(run_id))\n",
    "\n",
    "hs_change_sql = '''\n",
    "    SELECT o.parcel_id, j.name,  p.cap_jurisdiction_id, p.jurisdiction_id, p.mgra_id, p.luz_id,\n",
    "    unit_change as hs_change, source, capacity_type,year_simulation\n",
    "      FROM urbansim.urbansim.urbansim_lite_output o \n",
    "      JOIN urbansim.urbansim.parcel p on p.parcel_id = o.parcel_id\n",
    "      JOIN urbansim.ref.jurisdiction j on p.cap_jurisdiction_id = j.jurisdiction_id\n",
    "     WHERE run_id =  %s\n",
    "  ORDER BY j.name,p.jurisdiction_id, year_simulation'''\n",
    "hs_change_sql = hs_change_sql % run_id\n",
    "hs = pd.read_sql(hs_change_sql,mssql_engine)\n",
    "units_added = int(hs.hs_change.sum())\n",
    "\n",
    "print(\"\\nUnits added: {:,} \".\\\n",
    "      format(units_added))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation output\n",
    "units = pd.merge(hs,xref_geography_df,left_on='mgra_id',right_on='mgra_13',how='left')\n",
    "units.loc[units.cap_jurisdiction_id == 19,'jcid'] = units['cocpa_2016']\n",
    "units.loc[units.cap_jurisdiction_id == 14,'jcid'] = units['cicpa_13']\n",
    "units['jcid'].fillna(units['cap_jurisdiction_id'],inplace=True)\n",
    "# manually assign CPA to mgra 19415, 18831\n",
    "units.loc[units.mgra_id==19415,'jcid'] = 1909\n",
    "units.loc[units.mgra_id==18831,'jcid'] = 1909\n",
    "print(units.loc[units.jcid.isnull()])\n",
    "print(units.loc[units.jcid==14])\n",
    "print(units.loc[units.jcid==19])\n",
    "units.parcel_id = units.parcel_id.astype(int)\n",
    "units.jcid = units.jcid.astype(int)\n",
    "units.set_index('jcid',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jcids = units.index.unique().tolist()\n",
    "CPAs_no_unit_change = np.setdiff1d(CPAs,jcids).tolist()\n",
    "print(CPAs_no_unit_change)\n",
    "for cpa in CPAs_no_unit_change:\n",
    "    units.loc[cpa] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.reset_index(inplace=True)\n",
    "print(len(units.jcid.unique()))\n",
    "units.fillna(0,inplace=True)\n",
    "units = pd.merge(units,cocpa_names,left_on='jcid',right_on='cocpa_id',how = 'left')\n",
    "units = pd.merge(units,cicpa_names,left_on='jcid',right_on='cicpa_id',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jur_name_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = pd.merge(units,jur_name_df,left_on='jurisdiction_2016',right_on='jurisdiction_id_data_cafe',how = 'left')\n",
    "units['jcname'] = units['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.loc[units.jcid>=1900,'jcname'] = units['cocpa']\n",
    "units.loc[(units.jcid>=1400) & (units.jcid<1900),'jcname'] = units['cicpa']\n",
    "units.loc[units.jcname==0,'jcname'] = units['jurisdiction']\n",
    "print(units.sort_values(by='jcid').jcid.unique())\n",
    "print(len(units.jcname.unique()))\n",
    "units.loc[units.year_simulation==0,'year_simulation'] = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# units.loc[units.jcname=='Barrio Logan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs2 = units.copy()\n",
    "hs2.replace('cc', 'sgoa',inplace=True)\n",
    "hs2.replace('mc', 'sgoa',inplace=True)\n",
    "hs2.replace('tc', 'sgoa',inplace=True)\n",
    "hs2.replace('tco', 'sgoa',inplace=True)\n",
    "hs2.replace('uc', 'sgoa',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = range(2015,2055,5)\n",
    "names = [str(x) for x in range(2020,2055,5)]\n",
    "hs2['increment'] = pd.cut(hs2.year_simulation, bins, labels=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \"jcid\",\"geo\"\n",
    "units_added_by_capacity_type_and_yr = pd.DataFrame({'units_by_type': hs2.\n",
    "                                          groupby([\"jcid\",\"jcname\",\"increment\",\"capacity_type\"])\n",
    "                                          .hs_change.sum()}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolist = units_added_by_capacity_type_and_yr.jcname.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geolist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_added_by_capacity_type_and_yr.set_index(['jcid','jcname','increment','capacity_type'],inplace=True)\n",
    "units_added_by_capacity_type_and_yr = units_added_by_capacity_type_and_yr.unstack(['jcid','jcname'])\n",
    "units_added_by_capacity_type_and_yr.fillna(0,inplace=True)\n",
    "units_added_by_capacity_type_and_yr = units_added_by_capacity_type_and_yr.stack(['jcid','jcname'])\n",
    "units_added_by_capacity_type_and_yr.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "c = units_added_by_capacity_type_and_yr.loc[units_added_by_capacity_type_and_yr.jcid==1]\n",
    "#1402"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "type_pivot = c.pivot(index='increment', columns='capacity_type', values='units_by_type').\\\n",
    "        reset_index().rename_axis(None, axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tablular data\n",
    "assigned_parcel_sql = '''\n",
    "SELECT  a.parcel_id, cap_jurisdiction_id, jurisdiction_id, a.du, a.type,p.mgra_id\n",
    "   FROM [urbansim].[urbansim].[additional_capacity] a\n",
    "   JOIN urbansim.parcel p on p.parcel_id = a.parcel_id\n",
    "  WHERE version_id = %s'''\n",
    "assigned_parcel_sql = assigned_parcel_sql % versions['additional_capacity_version']\n",
    "assigned_df = pd.read_sql(assigned_parcel_sql, mssql_engine)\n",
    "assigned_df.replace('cc', 'sgoa',inplace=True)\n",
    "assigned_df.replace('mc', 'sgoa',inplace=True)\n",
    "assigned_df.replace('tc', 'sgoa',inplace=True)\n",
    "assigned_df.replace('tco', 'sgoa',inplace=True)\n",
    "assigned_df.replace('uc', 'sgoa',inplace=True)\n",
    "assigned_df_1 = assigned_df.loc[assigned_df.cap_jurisdiction_id==1]\n",
    "assigned_capacity_1 = int(assigned_df_1.du.sum())\n",
    "assigned_capacity_adu = int(assigned_df_1.loc[assigned_df.type=='adu'].du.sum())\n",
    "assigned_capacity_sgoa = int(assigned_df_1.loc[assigned_df.type=='sgoa'].du.sum())\n",
    "\n",
    "print(\"\\nCapacity from urbansim.additional_capacity (ADU and SGOAs): {:,}\".format(assigned_capacity_1))\n",
    "print(\"\\nCapacity from urbansim.additional_capacity (ADU): {:,}\".format(assigned_capacity_adu))\n",
    "print(\"\\nCapacity from urbansim.additional_capacity (SGOAs): {:,}\".format(assigned_capacity_sgoa))\n",
    "# assigned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tablular data\n",
    "assigned_df.replace('cc', 'sgoa',inplace=True)\n",
    "assigned_df.replace('mc', 'sgoa',inplace=True)\n",
    "assigned_df.replace('tc', 'sgoa',inplace=True)\n",
    "assigned_df.replace('tco', 'sgoa',inplace=True)\n",
    "assigned_df.replace('uc', 'sgoa',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tablular data\n",
    "assignedcpa = pd.merge(assigned_df,xref_geography_df,left_on='mgra_id',right_on='mgra_13',how='left')\n",
    "assignedcpa.loc[assignedcpa.cap_jurisdiction_id == 19,'jcid'] = assignedcpa['cocpa_2016']\n",
    "assignedcpa.loc[assignedcpa.cap_jurisdiction_id == 14,'jcid'] = assignedcpa['cicpa_13']\n",
    "assignedcpa['jcid'].fillna(assignedcpa['cap_jurisdiction_id'],inplace=True)\n",
    "assignedcpa.loc[assignedcpa.mgra_id==19415,'jcid'] = 1909\n",
    "assignedcpa.loc[assignedcpa.mgra_id==18831,'jcid'] = 1909\n",
    "assignedcpa.loc[assignedcpa.mgra_id==11514.0,'jcid'] = 13\n",
    "assignedcpa.loc[assignedcpa.mgra_id==7521.0,'jcid'] = 3\n",
    "assignedcpa.loc[assignedcpa.mgra_13==7259,'jcid'] = 1439 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tablular data\n",
    "sched_dev_parcel_sql = '''\n",
    "SELECT s.parcel_id, p.jurisdiction_id, p.cap_jurisdiction_id,capacity_3,mgra_id\n",
    "FROM [urbansim].[urbansim].[scheduled_development_parcel] s\n",
    "JOIN [urbansim].[urbansim].[parcel] p\n",
    "ON p.parcel_id = s.parcel_id'''\n",
    "sched_dev_df = pd.read_sql(sched_dev_parcel_sql, mssql_engine)\n",
    "sched_dev_df_1 = sched_dev_df.loc[sched_dev_df.cap_jurisdiction_id==1]\n",
    "sched_dev_capacity_1 = int(sched_dev_df_1.capacity_3.sum())\n",
    "print(\"\\nScheduled development capacity from urbansim.scheduled_development_parcel : {:,}\".\\\n",
    "      format(sched_dev_capacity_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tablular data\n",
    "sunits = pd.merge(sched_dev_df,xref_geography_df,left_on='mgra_id',right_on='mgra_13',how='left')\n",
    "sunits.loc[sunits.cap_jurisdiction_id == 19,'jcid'] = sunits['cocpa_2016']\n",
    "sunits.loc[sunits.cap_jurisdiction_id == 14,'jcid'] = sunits['cicpa_13']\n",
    "sunits['jcid'].fillna(sunits['cap_jurisdiction_id'],inplace=True)\n",
    "sunits.loc[sunits.mgra_id==19415,'jcid'] = 1909\n",
    "sunits.loc[sunits.mgra_id==18831,'jcid'] = 1909\n",
    "sunits.loc[sunits.mgra_id==11514.0,'jcid'] = 13\n",
    "sunits.loc[sunits.mgra_id==7521.0,'jcid'] = 3\n",
    "sunits.loc[sunits.mgra_13==7259,'jcid'] = 1439 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched_dev_df_1 = sunits.loc[sunits.jcid==1404]\n",
    "sched_dev_capacity_1 = int(sched_dev_df_1.capacity_3.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched_dev_capacity_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tablular data\n",
    "parcel_capacity_sql = '''\n",
    "    SELECT [parcel_id],[jurisdiction_id],[cap_jurisdiction_id],[site_id],mgra_id,\n",
    "           [du_2015],[du_2017],[capacity_1],[capacity_2]\n",
    "      FROM [urbansim].[urbansim].[parcel]'''\n",
    "capacity_df = pd.read_sql(parcel_capacity_sql,mssql_engine)\n",
    "capacity_df_1 = capacity_df.loc[capacity_df.cap_jurisdiction_id==1]\n",
    "urbansim_parcel_capacity_1 = int(capacity_df_1.loc[capacity_df_1.site_id.isnull()].capacity_2.sum())\n",
    "print(\"\\nCapacity from urbansim.parcel where site id is null: {:,}\".format(urbansim_parcel_capacity_1))\n",
    "# 291,989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tablular data\n",
    "units = pd.merge(capacity_df,xref_geography_df,left_on='mgra_id',right_on='mgra_13',how='left')\n",
    "units.loc[units.cap_jurisdiction_id == 19,'jcid'] = units['cocpa_2016']\n",
    "units.loc[units.cap_jurisdiction_id == 14,'jcid'] = units['cicpa_13']\n",
    "units['jcid'].fillna(units['cap_jurisdiction_id'],inplace=True)\n",
    "print(len(units))\n",
    "print(len(capacity_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tablular data\n",
    "# manually assign CPA or jurisdiction to mgra 19415,11514,18831\n",
    "units.loc[units.mgra_id==19415,'jcid'] = 1909\n",
    "units.loc[units.mgra_id==18831,'jcid'] = 1909\n",
    "units.loc[units.mgra_id==11514.0,'jcid'] = 13\n",
    "units.loc[units.mgra_id==7521.0,'jcid'] = 3\n",
    "units.loc[units.mgra_13==7259,'jcid'] = 1439 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capacity_df_1 = units.loc[units.jcid==city_cpa_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# city_cpa_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC tabular data\n",
    "# units.loc[units.jcid==1999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tabular data\n",
    "run_id_sql = '''\n",
    "SELECT max(run_id)\n",
    "  FROM [urbansim].[urbansim].[urbansim_lite_output]\n",
    "'''\n",
    "run_id_df = pd.read_sql(run_id_sql, mssql_engine)\n",
    "run_id = int(run_id_df.values)\n",
    "print(\"\\nRun id : {:,}\".format(run_id))\n",
    "\n",
    "hs_change_sql = '''\n",
    "    SELECT o.parcel_id, j.name,  p.cap_jurisdiction_id, p.jurisdiction_id, p.mgra_id, p.luz_id,\n",
    "    unit_change as hs_change, source, capacity_type,year_simulation\n",
    "      FROM urbansim.urbansim.urbansim_lite_output o \n",
    "      JOIN urbansim.urbansim.parcel p on p.parcel_id = o.parcel_id\n",
    "      JOIN urbansim.ref.jurisdiction j on p.cap_jurisdiction_id = j.jurisdiction_id\n",
    "     WHERE run_id =  %s\n",
    "  ORDER BY j.name,p.jurisdiction_id, year_simulation'''\n",
    "hs_change_sql = hs_change_sql % run_id\n",
    "hs = pd.read_sql(hs_change_sql,mssql_engine)\n",
    "units_added = int(hs.hs_change.sum())\n",
    "\n",
    "print(\"\\nUnits added: {:,} \".\\\n",
    "      format(units_added))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tablular data\n",
    "hscpa = pd.merge(hs,xref_geography_df,left_on='mgra_id',right_on='mgra_13',how='left')\n",
    "hscpa.loc[hscpa.cap_jurisdiction_id == 19,'jcid'] = hscpa['cocpa_2016']\n",
    "hscpa.loc[hscpa.cap_jurisdiction_id == 14,'jcid'] = hscpa['cicpa_13']\n",
    "hscpa['jcid'].fillna(hscpa['cap_jurisdiction_id'],inplace=True)\n",
    "hscpa.loc[hscpa.mgra_id==19415,'jcid'] = 1909\n",
    "hscpa.loc[hscpa.mgra_id==18831,'jcid'] = 1909\n",
    "hscpa.loc[hscpa.mgra_id==11514.0,'jcid'] = 13\n",
    "hscpa.loc[hscpa.mgra_id==7521.0,'jcid'] = 3\n",
    "hscpa.loc[hscpa.mgra_13==7259,'jcid'] = 1439 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hscpa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = os.path.join(os.getcwd(),'plots/barplots4')#,datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "# 'run_'+str(run_id) + '_city_cpa')\n",
    "try:\n",
    "    os.stat(dirname)\n",
    "except:\n",
    "    os.mkdir(dirname)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolist[18:19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use this for bar plots and tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, jur in enumerate(geolist):\n",
    "        c = units_added_by_capacity_type_and_yr.loc[units_added_by_capacity_type_and_yr.jcname==jur]\n",
    "        type_pivot = c.pivot(index='increment', columns='capacity_type', values='units_by_type').\\\n",
    "        reset_index().rename_axis(None, axis=1)\n",
    "        \n",
    "\n",
    "        type_pivot.set_index('increment',inplace=True)\n",
    "        type_pivot.fillna(0,inplace=True)\n",
    "        type_pivot = type_pivot[['sch', 'jur', 'adu', 'sgoa']]\n",
    "        type_pivot['sch'] = type_pivot['sch'].cumsum()\n",
    "        type_pivot['jur'] = type_pivot['jur'].cumsum()\n",
    "        type_pivot['adu'] = type_pivot['adu'].cumsum()\n",
    "        type_pivot['sgoa'] = type_pivot['sgoa'].cumsum()\n",
    "        \n",
    "        city_cpa_id = c.iloc[0]['jcid']\n",
    "        \n",
    "        ax = type_pivot.plot.bar(stacked=True,rot=0)\n",
    "\n",
    "        ptitle = 'DRAFT Cumulative Housing Units Added By Capacity Type\\n' + jur + ' (id=' +  str(city_cpa_id) + ')'\n",
    "        ax.set_ylabel(\"Housing units added\",size=14)\n",
    "        ax.set_title(ptitle,size=14)\n",
    "        ax.set_xlabel(\"Year\",size=14)\n",
    "\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(6, 4.5)\n",
    "        jur_ = jur.replace(\":\", \"_\") # colon not allowed in windows filename\n",
    "        plotname = dirname + '//' + str(run_id) + '_city_cpa_' + str(city_cpa_id) + '_' + jur_ + 'bar.png'\n",
    "        fig.savefig(plotname, bbox_inches='tight',dpi=200)\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "        \n",
    "        # table\n",
    "        c = units_added_by_capacity_type_and_yr.loc[units_added_by_capacity_type_and_yr.jcname==jur]\n",
    "        type_pivot = c.pivot(index='increment', columns='capacity_type', values='units_by_type').\\\n",
    "        reset_index().rename_axis(None, axis=1)\n",
    "        hs_1 = hscpa.loc[hscpa.jcid==city_cpa_id]\n",
    "        units_added = int(hs_1.hs_change.sum())\n",
    "        \n",
    "        type_pivot.set_index('increment',inplace=True)\n",
    "        type_pivot.fillna(0,inplace=True)\n",
    "        type_pivot = type_pivot[['sch', 'jur', 'adu', 'sgoa']]\n",
    "        sum_sgoa = int(type_pivot.sgoa.sum())\n",
    "        sum_adu = int(type_pivot.adu.sum())\n",
    "        sum_jur = int(type_pivot.jur.sum())\n",
    "        sum_sch = int(type_pivot.sch.sum())\n",
    "\n",
    "        type_pivot.sgoa.fillna(0,inplace=True)\n",
    "        type_pivot.adu.fillna(0,inplace=True)\n",
    "        type_pivot.jur.fillna(0,inplace=True)\n",
    "        type_pivot.sch.fillna(0,inplace=True)\n",
    "        if units_added == 0:\n",
    "            percent_total = str(0) + '%'\n",
    "            percent_sch = str(0) + '%'\n",
    "            percent_jur = str(0) + '%'\n",
    "            percent_adu = str(0) + '%'\n",
    "            percent_sgoa = str(0) + '%'\n",
    "        else:\n",
    "            percent_total = str(round(units_added/units_added * 100)) + '%'\n",
    "            percent_sch = str(round(sum_sch/units_added * 100)) + '%'\n",
    "            percent_jur = str(round(sum_jur/units_added * 100)) + '%'\n",
    "            percent_adu = str(round(sum_adu/units_added * 100)) + '%'\n",
    "            percent_sgoa = str(round(sum_sgoa/units_added * 100)) + '%'\n",
    "        \n",
    "        assigned_df_1 = assignedcpa.loc[assignedcpa.jcid==city_cpa_id]\n",
    "        assigned_capacity_1 = int(assigned_df_1.du.sum())\n",
    "        assigned_capacity_adu = int(assigned_df_1.loc[assigned_df.type=='adu'].du.sum())\n",
    "        assigned_capacity_sgoa = int(assigned_df_1.loc[assigned_df.type=='sgoa'].du.sum())\n",
    "        sched_dev_df_1 = sunits.loc[sunits.jcid==city_cpa_id]\n",
    "        sched_dev_capacity_1 = int(sched_dev_df_1.capacity_3.sum())\n",
    "        capacity_df_1 = units.loc[units.jcid==city_cpa_id]\n",
    "        urbansim_parcel_capacity_1 = int(capacity_df_1.loc[capacity_df_1.site_id.isnull()].capacity_2.sum())\n",
    "        total_capacity_1 = assigned_capacity_1 + sched_dev_capacity_1 + urbansim_parcel_capacity_1\n",
    "        remaining_total = total_capacity_1 - units_added\n",
    "        remaining_sch = sched_dev_capacity_1 - sum_sch\n",
    "        remaining_jur = urbansim_parcel_capacity_1 - sum_jur\n",
    "        remaining_adu = assigned_capacity_adu - sum_adu\n",
    "        remaining_sgoa = assigned_capacity_sgoa - sum_sgoa\n",
    "        share_count = pd.DataFrame({'Total Units Added' : [sum_sch,sum_jur,sum_adu,sum_sgoa,units_added],\\\n",
    "                            'Percentage Units Added' : [percent_sch,percent_jur,percent_adu,\\\n",
    "                                                        percent_sgoa,percent_total],\\\n",
    "                            'Total Capacity' : [sched_dev_capacity_1,urbansim_parcel_capacity_1,\\\n",
    "                                               assigned_capacity_adu,assigned_capacity_sgoa,total_capacity_1],\n",
    "                           'Remaining Capacity' : [remaining_sch,remaining_jur,remaining_adu,\\\n",
    "                                                   remaining_sgoa,remaining_total]},\n",
    "                     index=['Scheduled Development','Jurisdiction Provided','Additional Dwelling Units',\\\n",
    "                            'SGOA Additional Capacity','Total'])\n",
    "        cols = ['Total Units Added','Percentage Units Added','Total Capacity','Remaining Capacity']\n",
    "        share_count = share_count[cols] \n",
    "        share_count.index.name = 'Housing Units by Capacity Type'\n",
    "        fig, ax = plt.subplots(figsize=(12, 4)) # set size frame\n",
    "        ax.xaxis.set_visible(False)  # hide the x axis\n",
    "        ax.yaxis.set_visible(False)  # hide the y axis\n",
    "        ax.set_frame_on(False)  # no visible frame, uncomment if size is ok\n",
    "        tabla = table(ax, share_count, loc='upper right', colWidths=[0.18, 0.25, 0.16, 0.20])  \n",
    "        # colWidths=[0.22]*len(share_count.columns)\n",
    "        tabla.auto_set_font_size(False) # Activate set fontsize manually\n",
    "        tabla.set_fontsize(12) # if ++fontsize is necessary ++colWidths\n",
    "        #tabla.scale(1.2, 1.2) # change size table\n",
    "        tabla.scale(1, 4)\n",
    "        plotname = dirname + '//' + str(run_id) + '_city_cpa_' + str(city_cpa_id) + '_' + jur_ + 'percent_capacity_type_table.png'\n",
    "\n",
    "        plt.savefig(plotname, bbox_inches=\"tight\",transparent=True)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = os.path.join(os.getcwd(),'plots/tables3')#,datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "# 'run_'+str(run_id) + '_city_cpa')\n",
    "try:\n",
    "    os.stat(dirname)\n",
    "except:\n",
    "    os.mkdir(dirname)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lambda total_chg_sr13: if total_chg_sr13 == 0: 0 else: total_chg_sr14 / total_chg_sr13 * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, jur in enumerate(geolist):\n",
    "    jur_ = jur.replace(\":\", \"_\") # colon not allowed in windows filename\n",
    "    c = units_added_by_capacity_type_and_yr.loc[units_added_by_capacity_type_and_yr.jcname==jur]\n",
    "    city_cpa_id = c.iloc[0]['jcid']\n",
    "    # sr14_geo_df_pivot[[jur]]\n",
    "    # sr13_geo_df_pivot[[jur]]\n",
    "    hs_base_sr13 = int(sr13_geo_df_pivot[[jur]].loc[2012].values[0])\n",
    "    hs_base_sr14 = int(sr14_geo_df_pivot[[jur]].loc[2017].values[0])\n",
    "    hs_final_sr13 = int(sr13_geo_df_pivot[[jur]].loc[2050].values[0])\n",
    "    hs_final_sr14 = int(sr14_geo_df_pivot[[jur]].loc[2050].values[0])\n",
    "    scheddev_sr13 = int(sr13_sched_dev_totals.loc[ sr13_sched_dev_totals['geo']==jur].iloc[0]['sched_dev_sum'])\n",
    "    scheddev_sr14 = int(sr14_source1.loc[sr14_source1['geo']==jur].iloc[0]['hs_sum'])\n",
    "    total_chg_sr13 = int(sr13_totalchange.loc[jur][0])\n",
    "    total_chg_sr14 = int(sr14_increment.loc[(sr14_increment.increment==2050) & (sr14_increment.geo==jur)].hs_cumulative)\n",
    "    NOT_scheddev_sr13 = total_chg_sr13 - scheddev_sr13\n",
    "    NOT_scheddev_sr14 = total_chg_sr14 - scheddev_sr14\n",
    "\n",
    "    if hs_base_sr13 == 0:\n",
    "        percent_sr13 = str(0) + '%'       \n",
    "    else:\n",
    "        percent_sr13 = str(round(total_chg_sr13/hs_base_sr13 * 100)) + '%'\n",
    "    if hs_base_sr14 == 0:\n",
    "        percent_sr14 = str(0) + '%'         \n",
    "    else:\n",
    "        percent_sr14 = str(round(total_chg_sr14/hs_base_sr14 * 100)) + '%'\n",
    "    \n",
    "    sr13_sr14_hs = pd.DataFrame({'sr13' : [hs_base_sr13,hs_final_sr13,total_chg_sr13,\n",
    "                                       scheddev_sr13,NOT_scheddev_sr13,percent_sr13],\\\n",
    "                            'sr14' : [hs_base_sr14,hs_final_sr14,total_chg_sr14,\\\n",
    "                                      scheddev_sr14, NOT_scheddev_sr14,percent_sr14],\n",
    "                                'chg': [hs_base_sr14 - hs_base_sr13, hs_final_sr14 - hs_final_sr13,\n",
    "                                                     total_chg_sr14 - total_chg_sr13,\n",
    "                                                    scheddev_sr14 - scheddev_sr13,  NOT_scheddev_sr14 - NOT_scheddev_sr13,\n",
    "                                                  0]},\n",
    "                     index=['Base Year Housing Units (2012/2017)','Total Housing Units (2050)',\n",
    "                            'Total Change','Sched Dev',\n",
    "                            'Not Sched Dev','Total Percent Change'\n",
    "                            ])\n",
    "    #print(sr13_sr14_hs)\n",
    "    # sr13_sr14_hs\n",
    "    fig, ax = plt.subplots(figsize=(8, 4)) # set size frame\n",
    "    ax.xaxis.set_visible(False)  # hide the x axis\n",
    "    ax.yaxis.set_visible(False)  # hide the y axis\n",
    "    ax.set_frame_on(False)  # no visible frame, uncomment if size is ok\n",
    "    tabla = table(ax, sr13_sr14_hs, loc='upper right', colWidths=[0.16, 0.16, 0.16])\n",
    "    # colWidths=[0.22]*len(share_count.columns)\n",
    "    tabla.auto_set_font_size(False) # Activate set fontsize manually\n",
    "    tabla.set_fontsize(12) # if ++fontsize is necessary ++colWidths\n",
    "    #tabla.scale(1.2, 1.2) # change size table\n",
    "    tabla.scale(1, 4)\n",
    "    plotname = dirname + '//' + str(run_id) + '_city_cpa_' + str(city_cpa_id) + '_' + jur_ + 'forecast_comparison.png'\n",
    "    #plotname = dirname + '//' + str(run_id) + '_city_cpa_' + str(city_cpa_id) + '_' + jur_ + 'percent_capacity_type_table.png'\n",
    "    plt.savefig(plotname, bbox_inches=\"tight\",transparent=True)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capacity_df_1 = units.loc[units.cap_jurisdiction_id==city_cpa_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capacity_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# city_cpa_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_cpa_id = 1467\n",
    "sched_dev_df_1 = sched_dev_df.loc[sched_dev_df.cap_jurisdiction_id==city_cpa_id]\n",
    "sched_dev_capacity_1 = int(sched_dev_df_1.capacity_3.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched_dev_capacity_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jur='NCFUA Reserve'\n",
    "c = units_added_by_capacity_type_and_yr.loc[units_added_by_capacity_type_and_yr.jcname==jur]\n",
    "type_pivot = c.pivot(index='increment', columns='capacity_type', values='units_by_type').\\\n",
    "reset_index().rename_axis(None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity_df_1 = capacity_df.loc[capacity_df.cap_jurisdiction_id==1467]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_sch = int(type_pivot.sch.sum())\n",
    "sum_sch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(city_cpa_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned_df_1 = assigned_df.loc[assigned_df.cap_jurisdiction_id==int(city_cpa_id)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "type_pivot = c.pivot\\\n",
    "(index='increment', columns='capacity_type', values='units_by_type').\\\n",
    "reset_index().rename_axis(None, axis=1)\n",
    "\n",
    "type_pivot.sgoa.fillna(0,inplace=True)\n",
    "type_pivot.adu.fillna(0,inplace=True)\n",
    "type_pivot.jur.fillna(0,inplace=True)\n",
    "type_pivot.sch.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "type_pivot.set_index('increment',inplace=True)\n",
    "type_pivot = type_pivot[['sch', 'jur', 'adu', 'sgoa']]\n",
    "type_pivot['sch'] = type_pivot['sch'].cumsum()\n",
    "type_pivot['jur'] = type_pivot['jur'].cumsum()\n",
    "type_pivot['adu'] = type_pivot['adu'].cumsum()\n",
    "type_pivot['sgoa'] = type_pivot['sgoa'].cumsum()\n",
    "# type_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "city_cpa_id = 1\n",
    "jur = 'Carlsbad'\n",
    "\n",
    "ax = type_pivot.plot.bar(stacked=True,rot=0)\n",
    "\n",
    "ptitle = 'DRAFT Cumulative Housing Units Added By Capacity Type\\n' + jur + ' (id=' +  str(city_cpa_id) + ')'\n",
    "ax.set_ylabel(\"Housing units added\",size=14)\n",
    "ax.set_title(ptitle,size=14)\n",
    "ax.set_xlabel(\"Year\",size=14)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(6, 4.5)\n",
    "fig.savefig('plots/test/bar_capacity_type.png', bbox_inches='tight',dpi=200)\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bar chart"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# get max run id from urbansim\n",
    "run_id_sql = '''\n",
    "SELECT max(run_id)\n",
    "  FROM [urbansim].[urbansim].[urbansim_lite_output]\n",
    "'''\n",
    "run_id_df = pd.read_sql(run_id_sql, mssql_engine)\n",
    "run_id = int(run_id_df.values)\n",
    "print(\"\\nRun id : {:,}\".format(run_id))\n",
    "\n",
    "hs_change_sql = '''\n",
    "    SELECT o.parcel_id, j.name,  p.cap_jurisdiction_id, p.jurisdiction_id, p.mgra_id, p.luz_id,\n",
    "    unit_change as hs_change, source, capacity_type,year_simulation\n",
    "      FROM urbansim.urbansim.urbansim_lite_output o \n",
    "      JOIN urbansim.urbansim.parcel p on p.parcel_id = o.parcel_id\n",
    "      JOIN urbansim.ref.jurisdiction j on p.cap_jurisdiction_id = j.jurisdiction_id\n",
    "     WHERE run_id =  %s and p.cap_jurisdiction_id = 1\n",
    "  ORDER BY j.name,p.jurisdiction_id, year_simulation'''\n",
    "hs_change_sql = hs_change_sql % run_id\n",
    "hs = pd.read_sql(hs_change_sql,mssql_engine)\n",
    "units_added = int(hs.hs_change.sum())\n",
    "\n",
    "print(\"\\nUnits added: {:,} \".\\\n",
    "      format(units_added))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs2 = hs.copy()\n",
    "hs2.replace('cc', 'sgoa',inplace=True)\n",
    "hs2.replace('mc', 'sgoa',inplace=True)\n",
    "hs2.replace('tc', 'sgoa',inplace=True)\n",
    "hs2.replace('tco', 'sgoa',inplace=True)\n",
    "hs2.replace('uc', 'sgoa',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = range(2015,2055,5)\n",
    "names = [str(x) for x in range(2020,2055,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs2['increment'] = pd.cut(hs2.year_simulation, bins, labels=names)\n",
    "# hs2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_added_by_capacity_type_and_yr = pd.DataFrame({'units_by_type': hs2.\n",
    "                                          groupby([\"increment\",\"capacity_type\"])\n",
    "                                          .hs_change.sum()}).reset_index()\n",
    "# units_added_by_capacity_type_and_yr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_added_by_capacity_type_and_yr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_pivot = units_added_by_capacity_type_and_yr.pivot\\\n",
    "(index='increment', columns='capacity_type', values='units_by_type').\\\n",
    "reset_index().rename_axis(None, axis=1)\n",
    "# type_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_sgoa = int(type_pivot.sgoa.sum())\n",
    "sum_adu = int(type_pivot.adu.sum())\n",
    "sum_jur = int(type_pivot.jur.sum())\n",
    "sum_sch = int(type_pivot.sch.sum())\n",
    "\n",
    "type_pivot.sgoa.fillna(0,inplace=True)\n",
    "type_pivot.adu.fillna(0,inplace=True)\n",
    "type_pivot.jur.fillna(0,inplace=True)\n",
    "type_pivot.sch.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_pivot.set_index('increment',inplace=True)\n",
    "type_pivot = type_pivot[['sch', 'jur', 'adu', 'sgoa']]\n",
    "type_pivot['sch'] = type_pivot['sch'].cumsum()\n",
    "type_pivot['jur'] = type_pivot['jur'].cumsum()\n",
    "type_pivot['adu'] = type_pivot['adu'].cumsum()\n",
    "type_pivot['sgoa'] = type_pivot['sgoa'].cumsum()\n",
    "# type_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel_capacity_sql = '''\n",
    "    SELECT [parcel_id],[jurisdiction_id],[cap_jurisdiction_id],[site_id],\n",
    "           [du_2015],[du_2017],[capacity_1],[capacity_2]\n",
    "      FROM [urbansim].[urbansim].[parcel]'''\n",
    "capacity_df = pd.read_sql(parcel_capacity_sql,mssql_engine)\n",
    "capacity_df_1 = capacity_df.loc[capacity_df.cap_jurisdiction_id==1]\n",
    "urbansim_parcel_capacity_1 = int(capacity_df_1.loc[capacity_df_1.site_id.isnull()].capacity_2.sum())\n",
    "print(\"\\nCapacity from urbansim.parcel where site id is null: {:,}\".format(urbansim_parcel_capacity_1))\n",
    "# 291,989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched_dev_parcel_sql = '''\n",
    "SELECT s.parcel_id, p.jurisdiction_id, p.cap_jurisdiction_id,capacity_3 \n",
    "FROM [urbansim].[urbansim].[scheduled_development_parcel] s\n",
    "JOIN [urbansim].[urbansim].[parcel] p\n",
    "ON p.parcel_id = s.parcel_id'''\n",
    "sched_dev_df = pd.read_sql(sched_dev_parcel_sql, mssql_engine)\n",
    "sched_dev_df_1 = sched_dev_df.loc[sched_dev_df.cap_jurisdiction_id==1]\n",
    "sched_dev_capacity_1 = int(sched_dev_df_1.capacity_3.sum())\n",
    "print(\"\\nScheduled development capacity from urbansim.scheduled_development_parcel : {:,}\".\\\n",
    "      format(sched_dev_capacity_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned_parcel_sql = '''\n",
    "SELECT  a.parcel_id, cap_jurisdiction_id, jurisdiction_id, a.du, a.type\n",
    "   FROM [urbansim].[urbansim].[additional_capacity] a\n",
    "   JOIN urbansim.parcel p on p.parcel_id = a.parcel_id\n",
    "  WHERE version_id = %s'''\n",
    "assigned_parcel_sql = assigned_parcel_sql % versions['additional_capacity_version']\n",
    "assigned_df = pd.read_sql(assigned_parcel_sql, mssql_engine)\n",
    "assigned_df.replace('cc', 'sgoa',inplace=True)\n",
    "assigned_df.replace('mc', 'sgoa',inplace=True)\n",
    "assigned_df.replace('tc', 'sgoa',inplace=True)\n",
    "assigned_df.replace('tco', 'sgoa',inplace=True)\n",
    "assigned_df.replace('uc', 'sgoa',inplace=True)\n",
    "assigned_df_1 = assigned_df.loc[assigned_df.cap_jurisdiction_id==1]\n",
    "assigned_capacity_1 = int(assigned_df_1.du.sum())\n",
    "assigned_capacity_adu = int(assigned_df_1.loc[assigned_df.type=='adu'].du.sum())\n",
    "assigned_capacity_sgoa = int(assigned_df_1.loc[assigned_df.type=='sgoa'].du.sum())\n",
    "\n",
    "print(\"\\nCapacity from urbansim.additional_capacity (ADU and SGOAs): {:,}\".format(assigned_capacity_1))\n",
    "print(\"\\nCapacity from urbansim.additional_capacity (ADU): {:,}\".format(assigned_capacity_adu))\n",
    "print(\"\\nCapacity from urbansim.additional_capacity (SGOAs): {:,}\".format(assigned_capacity_sgoa))\n",
    "# assigned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_capacity_1 = assigned_capacity_1 + sched_dev_capacity_1 + urbansim_parcel_capacity_1\n",
    "total_capacity_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_total = total_capacity_1 - units_added\n",
    "remaining_sch = sched_dev_capacity_1 - sum_sch\n",
    "remaining_jur = urbansim_parcel_capacity_1 - sum_jur\n",
    "remaining_adu = assigned_capacity_adu - sum_adu\n",
    "remaining_sgoa = assigned_capacity_sgoa - sum_sgoa\n",
    "percent_total = str(round(units_added/units_added * 100)) + '%'\n",
    "percent_sch = str(round(sum_sch/units_added * 100)) + '%'\n",
    "percent_jur = str(round(sum_jur/units_added * 100)) + '%'\n",
    "percent_adu = str(round(sum_adu/units_added * 100)) + '%'\n",
    "percent_sgoa = str(round(sum_sgoa/units_added * 100)) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_count = pd.DataFrame({'Total Units Added' : [sum_sch,sum_jur,sum_adu,sum_sgoa,units_added],\\\n",
    "                            'Percentage Units Added' : [percent_sch,percent_jur,percent_adu,\\\n",
    "                                                        percent_sgoa,percent_total],\\\n",
    "                            'Total Capacity' : [sched_dev_capacity_1,urbansim_parcel_capacity_1,\\\n",
    "                                               assigned_capacity_adu,assigned_capacity_sgoa,total_capacity_1],\n",
    "                           'Remaining Capacity' : [remaining_sch,remaining_jur,remaining_adu,\\\n",
    "                                                   remaining_sgoa,remaining_total]},\n",
    "                     index=['Scheduled Development','Jurisdiction Provided','Additional Dwelling Units',\\\n",
    "                            'SGOA Additional Capacity','Total'])\n",
    "cols = ['Total Units Added','Percentage Units Added','Total Capacity','Remaining Capacity']\n",
    "share_count = share_count[cols] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_count.index.name = 'Housing Units by Capacity Type'\n",
    "share_count"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "city_cpa_id = 1\n",
    "jur = 'Carlsbad'\n",
    "\n",
    "ax = type_pivot.plot.bar(stacked=True,rot=0)\n",
    "\n",
    "ptitle = 'DRAFT Cumulative Housing Units Added By Capacity Type\\n' + jur + ' (id=' +  str(city_cpa_id) + ')'\n",
    "ax.set_ylabel(\"Housing units added\",size=14)\n",
    "ax.set_title(ptitle,size=14)\n",
    "ax.set_xlabel(\"Year\",size=14)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(6, 4.5)\n",
    "fig.savefig('plots/test/bar_capacity_type.png', bbox_inches='tight',dpi=200)\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "# plt.savefig('plots/test/bar_capacity_type.png',bbox_inches=\"tight\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4)) # set size frame\n",
    "ax.xaxis.set_visible(False)  # hide the x axis\n",
    "ax.yaxis.set_visible(False)  # hide the y axis\n",
    "ax.set_frame_on(False)  # no visible frame, uncomment if size is ok\n",
    "tabla = table(ax, share_count, loc='upper right', colWidths=[0.18, 0.25, 0.16, 0.20])  \n",
    "# colWidths=[0.22]*len(share_count.columns)\n",
    "tabla.auto_set_font_size(False) # Activate set fontsize manually\n",
    "tabla.set_fontsize(12) # if ++fontsize is necessary ++colWidths\n",
    "#tabla.scale(1.2, 1.2) # change size table\n",
    "tabla.scale(1, 4)\n",
    "plotname = dirname + '//' + str(run_id) + '_city_cpa_' + city_cpa_id + '_' + jur_ + '_percent_capacity_type_table.png'\n",
    "\n",
    "plt.savefig(plotname, bbox_inches=\"tight\",transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_count.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_geo_df_pivot[[jur]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr14_geo_df_pivot[[jur]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sr14_geo_df_pivot[[jur]]\n",
    "# sr13_geo_df_pivot[[jur]]\n",
    "hs_base_sr13 = int(sr13_geo_df_pivot[[jur]].loc[2012].values[0])\n",
    "hs_base_sr14 = int(sr14_geo_df_pivot[[jur]].loc[2017].values[0])\n",
    "hs_final_sr13 = int(sr13_geo_df_pivot[[jur]].loc[2050].values[0])\n",
    "hs_final_sr14 = int(sr14_geo_df_pivot[[jur]].loc[2050].values[0])\n",
    "scheddev_sr13 = int(sr13_sched_dev_totals.loc[ sr13_sched_dev_totals['geo']==jur].iloc[0]['sched_dev_sum'])\n",
    "scheddev_sr14 = int(sr14_source1.loc[sr14_source1['geo']==jur].iloc[0]['hs_sum'])\n",
    "total_chg_sr13 = int(sr13_totalchange.loc[jur][0])\n",
    "total_chg_sr14 = int(sr14_increment.loc[(sr14_increment.increment==2050) & (sr14_increment.geo==jur)].hs_cumulative)\n",
    "NOT_scheddev_sr13 = total_chg_sr13 - scheddev_sr13\n",
    "NOT_scheddev_sr14 = total_chg_sr14 - scheddev_sr14\n",
    "percent_sr13 = str(round(total_chg_sr13/hs_base_sr13 * 100)) + '%'\n",
    "percent_sr14 = str(round(total_chg_sr14/hs_base_sr14 * 100)) + '%'\n",
    "sr13_sr14_hs = pd.DataFrame({'sr13' : [hs_base_sr13,hs_final_sr13,total_chg_sr13,\n",
    "                                       scheddev_sr13,NOT_scheddev_sr13,percent_sr13],\\\n",
    "                            'sr14' : [hs_base_sr14,hs_final_sr14,total_chg_sr14,\\\n",
    "                                      scheddev_sr14, NOT_scheddev_sr14,percent_sr14]},\n",
    "                     index=['Total Housing Units (2012/2017)','Total Housing Units (2050)',\n",
    "                            'Total Change','Sched Dev',\n",
    "                            'Not Sched Dev','Total Percent Change'\n",
    "                            ])\n",
    "sr13_sr14_hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4)) # set size frame\n",
    "ax.xaxis.set_visible(False)  # hide the x axis\n",
    "ax.yaxis.set_visible(False)  # hide the y axis\n",
    "ax.set_frame_on(False)  # no visible frame, uncomment if size is ok\n",
    "tabla = table(ax, sr13_sr14_hs, loc='upper right', colWidths=[0.16, 0.16])  \n",
    "# colWidths=[0.22]*len(share_count.columns)\n",
    "tabla.auto_set_font_size(False) # Activate set fontsize manually\n",
    "tabla.set_fontsize(12) # if ++fontsize is necessary ++colWidths\n",
    "#tabla.scale(1.2, 1.2) # change size table\n",
    "tabla.scale(1, 4)\n",
    "plt.savefig('plots/test/forecast_comparison.png', bbox_inches=\"tight\",transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sr14_geo_df_pivot[[jur]]\n",
    "# sr13_geo_df_pivot[[jur]]\n",
    "hs_base_sr13 = int(sr13_geo_df_pivot[[jur]].loc[2012].values[0])\n",
    "hs_base_sr14 = int(sr14_geo_df_pivot[[jur]].loc[2017].values[0])\n",
    "hs_final_sr13 = int(sr13_geo_df_pivot[[jur]].loc[2050].values[0])\n",
    "hs_final_sr14 = int(sr14_geo_df_pivot[[jur]].loc[2050].values[0])\n",
    "scheddev_sr13 = int(sr13_sched_dev_totals.loc[ sr13_sched_dev_totals['geo']==jur].iloc[0]['sched_dev_sum'])\n",
    "scheddev_sr14 = int(sr14_source1.loc[sr14_source1['geo']==jur].iloc[0]['hs_sum'])\n",
    "total_chg_sr13 = int(sr13_totalchange.loc[jur][0])\n",
    "total_chg_sr14 = int(sr14_increment.loc[(sr14_increment.increment==2050) & (sr14_increment.geo==jur)].hs_cumulative)\n",
    "NOT_scheddev_sr13 = total_chg_sr13 - scheddev_sr13\n",
    "NOT_scheddev_sr14 = total_chg_sr14 - scheddev_sr14\n",
    "percent_sr13 = str(round(total_chg_sr13/hs_base_sr13 * 100)) + '%'\n",
    "percent_sr14 = str(round(total_chg_sr14/hs_base_sr14 * 100)) + '%'\n",
    "sr13_sr14_hs = pd.DataFrame({'sr13' : [hs_base_sr13,hs_final_sr13,total_chg_sr13,\n",
    "                                       scheddev_sr13,NOT_scheddev_sr13,percent_sr13],\\\n",
    "                            'sr14' : [hs_base_sr14,hs_final_sr14,total_chg_sr14,\\\n",
    "                                      scheddev_sr14, NOT_scheddev_sr14,percent_sr14]},\n",
    "                     index=['Total Housing Units (2012/2017)','Total Housing Units (2050)',\n",
    "                            'Total Change','Sched Dev',\n",
    "                            'Not Sched Dev','Total Percent Change'\n",
    "                            ])\n",
    "sr13_sr14_hs\n",
    "fig, ax = plt.subplots(figsize=(8, 4)) # set size frame\n",
    "ax.xaxis.set_visible(False)  # hide the x axis\n",
    "ax.yaxis.set_visible(False)  # hide the y axis\n",
    "ax.set_frame_on(False)  # no visible frame, uncomment if size is ok\n",
    "tabla = table(ax, sr13_sr14_hs, loc='upper right', colWidths=[0.16, 0.16])  \n",
    "# colWidths=[0.22]*len(share_count.columns)\n",
    "tabla.auto_set_font_size(False) # Activate set fontsize manually\n",
    "tabla.set_fontsize(12) # if ++fontsize is necessary ++colWidths\n",
    "#tabla.scale(1.2, 1.2) # change size table\n",
    "tabla.scale(1, 4)\n",
    "plt.savefig('plots/test/forecast_comparison.png', bbox_inches=\"tight\",transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_added_by_capacity_type_and_yr = pd.DataFrame({'units_by_type': hs2.\n",
    "                                          groupby([\"year_simulation\",\"capacity_type\"])\n",
    "                                          .hs_change.sum()}).reset_index()\n",
    "type_pivot2 = units_added_by_capacity_type_and_yr.pivot\\\n",
    "(index='year_simulation', columns='capacity_type', values='units_by_type').\\\n",
    "reset_index().rename_axis(None, axis=1)\n",
    "type_pivot2.fillna(0,inplace=True)\n",
    "type_pivot2.set_index('year_simulation',inplace=True)\n",
    "type_pivot2 = type_pivot2[['sch', 'jur', 'adu', 'sgoa']]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "labels = ['Total (added/capacity)\\n (' + str(units_added) + '/' + str(total_capacity_1) +  ')',\\\n",
    "          'sch (' + str(sum_sch) + '/' + str(sched_dev_capacity_1) + ')',\\\n",
    "          'jur (' + str(sum_jur) + '/' + str(urbansim_parcel_capacity_1) + ')',\\\n",
    "          'adu (' + str(sum_adu) + '/' + str(assigned_capacity_adu) + ')',\\\n",
    "          'sgoa (' + str(sum_sgoa) + '/' + str(assigned_capacity_sgoa) + ')']\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "type_pivot2['sch'] = type_pivot2['sch'].cumsum()\n",
    "type_pivot2['jur'] = type_pivot2['jur'].cumsum()\n",
    "type_pivot2['adu'] = type_pivot2['adu'].cumsum()\n",
    "type_pivot2['sgoa'] = type_pivot2['sgoa'].cumsum()\n",
    "\n",
    "city_cpa_id = 1\n",
    "jur = 'Carlsbad'\n",
    "\n",
    "\n",
    "\n",
    "ax = type_pivot2.plot.bar(stacked=True)\n",
    "ptitle = 'DRAFT Cumulative Housing Units Added By Capacity Type\\n' + jur + ' (' +  str(city_cpa_id) + ')'\n",
    "ax.set_ylabel(\"housing units added\",size=14)\n",
    "ax.set_title(ptitle,size=16) \n",
    "orig = ax.legend\n",
    "# ax.legend([\"sch (5)\", \"jur (10)\",\"adu (20)\",\"SGOA (15)\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "city_cpa_id = 1\n",
    "jur = 'Carlsbad'\n",
    "\n",
    "ax = type_pivot2.plot.bar(stacked=True)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "extra = Rectangle((0, 0), 1, 1, fc=\"w\", fill=False, edgecolor='none', linewidth=0)\n",
    "handles.insert(0,extra)\n",
    "labels.insert(0,'(added/capacity)')\n",
    "labels = ['Total (added/capacity)\\n (' + str(units_added) + '/' + str(total_capacity_1) +  ')',\\\n",
    "          'sch (' + str(sum_sch) + '/' + str(sched_dev_capacity_1) + ')',\\\n",
    "          'jur (' + str(sum_jur) + '/' + str(urbansim_parcel_capacity_1) + ')',\\\n",
    "          'adu (' + str(sum_adu) + '/' + str(assigned_capacity_adu) + ')',\\\n",
    "          'SGOA (' + str(sum_sgoa) + '/' + str(assigned_capacity_sgoa) + ')']\n",
    "ptitle = 'DRAFT Cumulative Housing Units Added By Capacity Type\\n' + jur + ' (citycpa_id=' +  str(city_cpa_id) + ')'\n",
    "ax.set_ylabel(\"housing units added\",size=14)\n",
    "ax.set_title(ptitle,size=16)\n",
    "leg = ax.legend(handles, labels,fontsize=12)\n",
    "# ax.set_xlabel(\"increment\")\n",
    "\n",
    "ax.set_xlabel(\"increment\\n\\n increment 2020 = (2017,2018,2019,2020)             \\nincrement 2025 = (2021, 2022, 2023, 2024, 2025)\\\n",
    "\\nincrement 2030 = (2026, 2027, 2028, 2029, 2030)\\nincrement 2035 = (2031, 2032, 2033, 2034, 2035)\\\n",
    "\\nincrement 2040 = (2036, 2037, 2038, 2039, 2040)\\nincrement 2045 = (2041, 2042, 2043, 2044, 2045)\\\n",
    "\\nincrement 2050 = (2046, 2047, 2048, 2049, 2050)\")\n",
    "# ax.legend([\"sch (5)\", \"jur (10)\",\"adu (20)\",\"SGOA (15)\"]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capty = pd.DataFrame({'Total' : [units_added,remaining_total,total_capacity_1],'sch' : [sum_sch, 0, sched_dev_capacity_1],\\\n",
    "                      'jur' : [sum_jur, 0, urbansim_parcel_capacity_1],\\\n",
    "                      'adu' : [sum_adu,618, assigned_capacity_adu],'sgoa' : [sum_sgoa, 160, assigned_capacity_sgoa]},\\\n",
    "                     index=['Units Added','Remaining Capacity','Total Capacity'])\n",
    "\n",
    "cols = ['Total','sch','jur','adu','sgoa']\n",
    "capty = capty[cols] "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4)) # set size frame\n",
    "ax.xaxis.set_visible(False)  # hide the x axis\n",
    "ax.yaxis.set_visible(False)  # hide the y axis\n",
    "ax.set_frame_on(False)  # no visible frame, uncomment if size is ok\n",
    "tabla = table(ax, capty, loc='upper right', colWidths=[0.17]*len(capty.columns))  # where df is your data frame\n",
    "tabla.auto_set_font_size(False) # Activate set fontsize manually\n",
    "tabla.set_fontsize(12) # if ++fontsize is necessary ++colWidths\n",
    "#tabla.scale(1.2, 1.2) # change size table\n",
    "tabla.scale(1, 4)\n",
    "plt.savefig('plots/test/capacity_type_table.png',bbox_inches=\"tight\", transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
