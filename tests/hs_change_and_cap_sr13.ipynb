{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sqlalchemy import create_engine\n",
    "from pysandag.database import get_connection_string\n",
    "\n",
    "db_connection_string = get_connection_string('..\\data\\config.yml', 'mssql_db')\n",
    "mssql_engine = create_engine(db_connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get output of sr13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get output of sr13: housing unit change grouped by jurisdiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_units_total_sql  = '''WITH hs2050 AS\n",
    "(SELECT y.City, x.increment, sum([hs]) AS hu\n",
    "    FROM [regional_forecast].[sr13_final].[capacity] x\n",
    "    inner join [regional_forecast].[sr13_final].[mgra13] AS y ON x.mgra = y.mgra\n",
    "    WHERE x.scenario = 0 and x.increment in (2050)  and hs > 0\n",
    "    GROUP BY y.City, x.increment), hs2012 AS\n",
    "(SELECT y.City, x.increment, sum([hs]) AS hu\n",
    "    FROM [regional_forecast].[sr13_final].[capacity] x\n",
    "    inner join [regional_forecast].[sr13_final].[mgra13] AS y ON x.mgra = y.mgra\n",
    "    WHERE x.scenario = 0 and x.increment in (2012) and hs > 0\n",
    "    GROUP BY y.City, x.increment)\n",
    "SELECT hs2012.City,hs2050.hu,hs2012.hu , hs2050.hu  - hs2012.hu as hu_change\n",
    "from hs2012 \n",
    "join hs2050 on hs2012.City = hs2050.City\n",
    "order by hs2012.City'''\n",
    "sr13_units_total = pd.read_sql(sr13_units_total_sql,mssql_engine)\n",
    "sr13_units_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sr13_sql_match_12to15 = '''\n",
    "     SELECT c.City, c.yr_from,ahu, c.yr_to,bhu, c.hu_change,hu_change_w_neg\n",
    "    FROM (SELECT  a.City, a.increment AS yr_from, b.increment AS yr_to\n",
    "     ,b.hu - a.hu as hu_change_w_neg\n",
    "    ,CASE WHEN b.hu - a.hu > 0 THEN b.hu - a.hu ELSE 0 END AS hu_change,\n",
    "    b.hu as bhu, a.hu as ahu\n",
    "    FROM (SELECT  y.City, x.increment, sum(x.hs) AS hu\n",
    "    FROM [regional_forecast].[sr13_final].[capacity] AS x\n",
    "    inner join [regional_forecast].[sr13_final].[mgra13] AS y ON x.mgra = y.mgra\n",
    "    WHERE x.increment in (2012)  and scenario = 0\n",
    "    GROUP BY  y.City, x.increment) AS a\n",
    "    inner join \n",
    "    (SELECT y.City,x.increment, sum(x.hs) AS hu\n",
    "    FROM [regional_forecast].[sr13_final].[capacity] AS x\n",
    "    inner join [regional_forecast].[sr13_final].[mgra13] AS y ON x.mgra = y.mgra\n",
    "    WHERE x.increment in (2015) and scenario = 0\n",
    "    GROUP BY  y.City, x.increment) AS b\n",
    "    ON a.City = b.City and a.increment = b.increment-3) AS c\n",
    "    ORDER BY yr_from, City\n",
    "'''\n",
    "sr13_units_by_jur_a = pd.read_sql(sr13_sql_match_12to15,mssql_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sr13_sql_match_15to50 = '''\n",
    "      SELECT c.City, c.yr_from,ahu, c.yr_to,bhu, c.hu_change,hu_change_w_neg\n",
    "    FROM (SELECT  a.City, a.increment AS yr_from, b.increment AS yr_to\n",
    "     ,b.hu - a.hu as hu_change_w_neg\n",
    "    ,CASE WHEN b.hu - a.hu > 0 THEN b.hu - a.hu ELSE 0 END AS hu_change,\n",
    "    b.hu as bhu, a.hu as ahu\n",
    "    FROM (SELECT  y.City, x.increment, sum(x.hs) AS hu\n",
    "    FROM [regional_forecast].[sr13_final].[capacity] AS x\n",
    "    inner join [regional_forecast].[sr13_final].[mgra13] AS y ON x.mgra = y.mgra\n",
    "    WHERE x.increment in (2015,2020, 2025, 2030, 2035, 2040, 2045, 2050)  and scenario = 0\n",
    "    GROUP BY  y.City, x.increment) AS a\n",
    "    inner join \n",
    "    (SELECT y.City,x.increment, sum(x.hs) AS hu\n",
    "    FROM [regional_forecast].[sr13_final].[capacity] AS x\n",
    "    inner join [regional_forecast].[sr13_final].[mgra13] AS y ON x.mgra = y.mgra\n",
    "    WHERE x.increment in (2015,2020, 2025, 2030, 2035, 2040, 2045, 2050) and scenario = 0\n",
    "    GROUP BY  y.City, x.increment) AS b\n",
    "    ON a.City = b.City and a.increment = b.increment-5) AS c\n",
    "    ORDER BY yr_from, City\n",
    "'''\n",
    "sr13_units_by_jur_b = pd.read_sql(sr13_sql_match_15to50,mssql_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sr13_units_by_jur = pd.concat([sr13_units_by_jur_a,sr13_units_by_jur_b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_units_by_jur.loc[sr13_units_by_jur.City==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_units_by_jur.loc[sr13_units_by_jur.City==4].hu_change.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_units_by_jur.loc[sr13_units_by_jur.City==4].hu_change_w_neg.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sr13_units = pd.DataFrame({'hs_added': sr13_units_by_jur.\n",
    "                           groupby([\"City\"]).\n",
    "                           hu_change.sum()}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_units.hs_added.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### capacity from [sr13_final].[capacity] (includes sched dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sr13_cap_by_jur_sql = '''\n",
    "    SELECT y.City,sum([cap_hs]) AS cap\n",
    "    FROM [regional_forecast].[sr13_final].[capacity] x\n",
    "    inner join [regional_forecast].[sr13_final].[mgra13] AS y ON x.mgra = y.mgra\n",
    "    WHERE x.scenario = 0 and x.increment in (2012) \n",
    "    GROUP BY y.City, x.increment\n",
    "    ORDER BY y.City'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sr13_cap_by_jur =  pd.read_sql(sr13_cap_by_jur_sql,mssql_engine,index_col='City')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sr13_cap_by_jur.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set increment as 'yr_to'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_units_by_jur.loc[sr13_units_by_jur.City==8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sr13_units_by_jur['increment'] = sr13_units_by_jur['yr_to']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sr13_units_by_jur = sr13_units_by_jur.drop(['yr_from', 'yr_to'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sr13_units_by_jur.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join sr13 unit change with capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "units_by_jur_inc = sr13_units_by_jur.set_index('City').join(sr13_cap_by_jur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_by_jur_inc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add starting year as 2012 with unit change as 0 (for plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_year = units_by_jur_inc.loc[units_by_jur_inc.increment==2025].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_year['increment'] = 2012\n",
    "start_year['hu_change'] = 0\n",
    "start_year['hu_change_neg'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "units_by_jur_inc = pd.concat([start_year,units_by_jur_inc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_by_jur_inc.loc[units_by_jur_inc.City==8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pivot for plotting so jurisdictions are columns and increments are rows with new units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "units_by_jur_inc.reset_index(inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "units_by_jur_pivot = units_by_jur_inc.pivot\\\n",
    "(index='increment', columns='City', values='hu_change_neg').\\\n",
    "reset_index().rename_axis(None, axis=1)\n",
    "units_by_jur_pivot.fillna(0,inplace=True)\n",
    "units_by_jur_pivot.set_index('increment',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# units_by_jur_pivot.loc[sr13_units_by_jur.City==8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_by_jur_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pivot for plotting so jurisdictions are columns and increments are rows with capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap_by_jur_pivot = units_by_jur_inc.pivot\\\n",
    "(index='increment', columns='City', values='cap').\\\n",
    "reset_index().rename_axis(None, axis=1)\n",
    "cap_by_jur_pivot.fillna(0,inplace=True)\n",
    "cap_by_jur_pivot.set_index('increment',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate cumulative sum of units added by jurisdiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "units_by_jur_pivot = units_by_jur_pivot.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for each jurisdiction join dataframe of new units and capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate remaining capacity by subtracting new units from starting capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(nrows=10, ncols=2)\n",
    "for j, jur in enumerate(units_by_jur_inc.City.unique().tolist()):\n",
    "    df_units_added = units_by_jur_pivot[[jur]]\n",
    "    df_capacity = cap_by_jur_pivot[[jur]]\n",
    "    df_plot = df_units_added.join(df_capacity, lsuffix='_new', rsuffix='_capacity')\n",
    "    hs_column = str(jur) + '_new'\n",
    "    cap_column = str(jur) + '_capacity'\n",
    "    cap_plot_column = str(jur) + '_cap'\n",
    "    df_plot[cap_plot_column] = df_plot[cap_column] - df_plot[hs_column]\n",
    "    del  df_plot[cap_column]\n",
    "    df_plot.plot(style='.-',ax=axes.flat[j],figsize=(10,32))\n",
    "   # df_plot.plot(kind='bar',ax=axes.flat[j],figsize=(10,32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_plot.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jur = 'Encinitas'\n",
    "jur_id = 6\n",
    "confluence_pg_cap = 2709\n",
    "jur = 'Imperial Beach'\n",
    "jur_id = 8\n",
    "confluence_pg_cap = 1840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{} housing unit change and remaining capacity\".format(jur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_units_added = units_by_jur_pivot[[jur_id]]\n",
    "df_units_added\n",
    "df_capacity = cap_by_jur_pivot[[jur_id]]\n",
    "df_capacity\n",
    "df_plot = df_units_added.join(df_capacity, lsuffix='_hs_change', rsuffix='_capacity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_units_added = units_by_jur_pivot[[jur_id]]\n",
    "df_capacity = cap_by_jur_pivot[[jur_id]]\n",
    "df_plot = df_units_added.join(df_capacity, lsuffix='_hs_change', rsuffix='_capacity')\n",
    "hs_column = str(jur_id) + '_hs_change'\n",
    "cap_column = str(jur_id) + '_capacity'\n",
    "cap_plot_column = str(jur_id) + '_cap'\n",
    "df_plot[cap_plot_column] = df_plot[cap_column] - df_plot[hs_column]\n",
    "del  df_plot[cap_column]\n",
    "df_plot.plot(style='.-',title=jur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## previous version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  missing 2015 increment\n",
    "\n",
    "sr13_sql_match_12to20 = '''\n",
    "    SELECT c.jurisdiction, c.jurisdiction_id, c.yr_from, c.yr_to, c.hu_change,hu_change_neg\n",
    "    FROM (SELECT a.jurisdiction, a.jurisdiction_id, a.yr_id AS yr_from, b.yr_id AS yr_to\n",
    "    ,b.hu - a.hu as hu_change_neg\n",
    "    ,CASE WHEN b.hu - a.hu > 0 THEN b.hu - a.hu ELSE 0 END AS hu_change\n",
    "    FROM (SELECT y.jurisdiction, y.jurisdiction_id, x.yr_id, sum(x.units) AS hu\n",
    "    FROM [demographic_warehouse].[fact].[housing] AS x\n",
    "    inner join [demographic_warehouse].[dim].[mgra_denormalize] AS y ON x.mgra_id = y.mgra_id\n",
    "    WHERE x.datasource_id = 13 and x.yr_id in (2012, 2020)\n",
    "    GROUP BY y.jurisdiction, y.jurisdiction_id, x.yr_id) AS a\n",
    "    inner join \n",
    "    (SELECT y.jurisdiction,y.jurisdiction_id,x.yr_id, sum(x.units) AS hu\n",
    "    FROM [demographic_warehouse].[fact].[housing] AS x\n",
    "    inner join [demographic_warehouse].[dim].[mgra_denormalize] AS y ON x.mgra_id = y.mgra_id\n",
    "    WHERE x.datasource_id = 13 and x.yr_id in (2012, 2020)\n",
    "    GROUP BY y.jurisdiction, y.jurisdiction_id, x.yr_id) AS b\n",
    "    ON a.jurisdiction_id = b.jurisdiction_id and a.yr_id = b.yr_id-8) AS c\n",
    "    ORDER BY yr_from, jurisdiction_id\n",
    "'''\n",
    "sr13_units_by_jur_a = pd.read_sql(sr13_sql_match_12to20,mssql_engine)\n",
    "sr13_sql_match_20to50 = '''\n",
    "    SELECT c.jurisdiction, c.jurisdiction_id, c.yr_from, c.yr_to, c.hu_change,hu_change_neg\n",
    "    FROM (SELECT a.jurisdiction, a.jurisdiction_id, a.yr_id AS yr_from, b.yr_id AS yr_to\n",
    "    ,b.hu - a.hu as hu_change_neg\n",
    "    ,CASE WHEN b.hu - a.hu > 0 THEN b.hu - a.hu ELSE 0 END AS hu_change\n",
    "    FROM (SELECT y.jurisdiction, y.jurisdiction_id, x.yr_id, sum(x.units) AS hu\n",
    "    FROM [demographic_warehouse].[fact].[housing] AS x\n",
    "    inner join [demographic_warehouse].[dim].[mgra_denormalize] AS y ON x.mgra_id = y.mgra_id\n",
    "    WHERE x.datasource_id = 13 and x.yr_id in (2020, 2025, 2030, 2035, 2040, 2045, 2050)\n",
    "    GROUP BY y.jurisdiction, y.jurisdiction_id, x.yr_id) AS a\n",
    "    inner join \n",
    "    (SELECT y.jurisdiction,y.jurisdiction_id,x.yr_id, sum(x.units) AS hu\n",
    "    FROM [demographic_warehouse].[fact].[housing] AS x\n",
    "    inner join [demographic_warehouse].[dim].[mgra_denormalize] AS y ON x.mgra_id = y.mgra_id\n",
    "    WHERE x.datasource_id = 13 and x.yr_id in (2020, 2025, 2030, 2035, 2040, 2045, 2050)\n",
    "    GROUP BY y.jurisdiction, y.jurisdiction_id, x.yr_id) AS b\n",
    "    ON a.jurisdiction_id = b.jurisdiction_id and a.yr_id = b.yr_id-5) AS c\n",
    "    ORDER BY yr_from, jurisdiction_id\n",
    "'''\n",
    "sr13_units_by_jur_b = pd.read_sql(sr13_sql_match_20to50,mssql_engine)\n",
    "\n",
    "sr13_units_by_jur = pd.concat([sr13_units_by_jur_a,sr13_units_by_jur_b])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
