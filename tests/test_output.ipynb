{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from pysandag.database import get_connection_string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_connection_string = get_connection_string('..\\data\\config.yml', 'mssql_db')\n",
    "mssql_engine = create_engine(db_connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current simulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_run_units_added_sql = '''\n",
    "SELECT  [units_index]\n",
    "      ,[parcel_id]\n",
    "      ,[units_added]\n",
    "      ,[year_simulation]\n",
    "      ,[run_id]\n",
    "  FROM [urbansim].[urbansim].[urbansim_lite_output_units]\n",
    "  where run_id = 1'''\n",
    "units_added_df =  pd.read_sql(current_run_units_added_sql, mssql_engine)\n",
    "units_added_df.drop('units_index',inplace=True,axis=1)\n",
    "units_added_df.drop('run_id',inplace=True,axis=1)\n",
    "units_added_df.sort_values(by=['parcel_id','year_simulation'],inplace=True)\n",
    "units_added_df.set_index('parcel_id',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous simulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "previous_run_units_sql = '''SELECT  [units_index]\n",
    "      ,[parcel_id]\n",
    "      ,[units_added]\n",
    "      ,[year_simulation]\n",
    "      ,[run_id]\n",
    "  FROM [urbansim].[urbansim].[urbansim_lite_output_units]\n",
    "  where run_id = 2'''\n",
    "previous_run =  pd.read_sql(previous_run_units_sql, mssql_engine)\n",
    "previous_run.drop('run_id',inplace=True,axis=1)\n",
    "previous_run.drop('units_index',inplace=True,axis=1)\n",
    "previous_run.rename(columns = {'year_built': 'year_simulation'},inplace=True)\n",
    "previous_run.rename(columns = {'residential_units': 'units_added'},inplace=True)\n",
    "previous_run.sort_values(by=['parcel_id','year_simulation'],inplace=True)\n",
    "previous_run.set_index('parcel_id',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"\\nDo the simulations produce the same results?\"\n",
    "print previous_run.equals(units_added_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Units added by jurisdiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parcels_sql = '''\n",
    "  WITH bldgs_by_parcel AS (SELECT parcel_id, SUM(residential_units) AS residential_units, \n",
    "                                  count(building_id) AS num_of_bldgs\n",
    "                           FROM   urbansim.urbansim.building GROUP BY parcel_id)\n",
    "  SELECT parcels.parcel_id, parcels.jurisdiction_id, parcels.site_id,\n",
    "         parcels.capacity, \n",
    "         COALESCE(bldgs_by_parcel.residential_units,0) AS residential_units,\n",
    "         COALESCE(bldgs_by_parcel.num_of_bldgs,0) AS bldgs,\n",
    "         0 as partial_build\n",
    "  FROM urbansim.urbansim.parcel parcels\n",
    "  LEFT JOIN bldgs_by_parcel \n",
    "  ON bldgs_by_parcel.parcel_id = parcels.parcel_id\n",
    "  WHERE parcels.capacity > 0\n",
    "'''\n",
    "parcels_df =  pd.read_sql(parcels_sql, mssql_engine,index_col='parcel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print previous_run.head()\n",
    "# print units_added_df.head()\n",
    "# print units_added_df.head()\n",
    "# print previous_run.tail()\n",
    "# print units_added_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_added_df.reset_index(inplace=True)\n",
    "units_added_w_city = units_added_df.join(parcels_df,on='parcel_id')\n",
    "print units_added_w_city.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_by_city = pd.DataFrame({'sr14_no_sched_dev': units_added_w_city .\n",
    "                                            groupby([\"jurisdiction_id\"]).\n",
    "                              units_added.sum()})\n",
    "\n",
    "# print units_by_city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to series 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr13_forecast_sql = ''' \n",
    "WITH sr13_capacity AS (\n",
    "SELECT  City,sum([hs]) as base_yr_hs_sr13\n",
    "      ,sum([cap_hs]) as capacity_sr13\n",
    "  FROM [regional_forecast].[sr13_final].[capacity] x\n",
    "  inner join [regional_forecast].[sr13_final].[mgra13] as y \n",
    "  on y.mgra = x.mgra\n",
    "   where scenario = 0 and increment = 2012 --and y.City = 1\n",
    "   GROUP BY City\n",
    "),\n",
    "sr13_2050 AS (\n",
    "SELECT  y.jurisdiction_id,yr_id, sum(units) as units2050\n",
    "FROM [demographic_warehouse].[fact].[housing] as x\n",
    "inner join [demographic_warehouse].[dim].[mgra_denormalize] as y \n",
    "on x.mgra_id = y.mgra_id\n",
    "where units > 0 and x.datasource_id = 13 and x.yr_id = 2050\n",
    "group by yr_id,y.jurisdiction_id\n",
    "),\n",
    "sr13_2012 AS (\n",
    "SELECT  y.jurisdiction_id,yr_id, sum(units) as units2012\n",
    "FROM [demographic_warehouse].[fact].[housing] as x\n",
    "inner join [demographic_warehouse].[dim].[mgra_denormalize] as y \n",
    "on x.mgra_id = y.mgra_id\n",
    "where units > 0 and x.datasource_id = 13 and x.yr_id = 2012\n",
    "group by yr_id,y.jurisdiction_id\n",
    ")\n",
    "SELECT sr13_2012.jurisdiction_id,base_yr_hs_sr13,capacity_sr13,sr13_2050.units2050 - sr13_2012.units2012 as forecast_sr13\n",
    "FROM sr13_2012 \n",
    "JOIN sr13_2050\n",
    "ON sr13_2012.jurisdiction_id = sr13_2050.jurisdiction_id\n",
    "JOIN sr13_capacity\n",
    "ON sr13_capacity.City = sr13_2012.jurisdiction_id\n",
    "order by sr13_2012 .jurisdiction_id\n",
    "'''\n",
    "sr13_forecast =  pd.read_sql(sr13_forecast_sql, mssql_engine,index_col='jurisdiction_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched_dev_sql = '''\n",
    "select jurisdiction_id, sum(capacity) as sr14_sched_dev \n",
    "from urbansim.urbansim.parcel\n",
    "where  site_id is NOT NULL\n",
    "group by jurisdiction_id\n",
    "order by jurisdiction_id\n",
    "'''\n",
    "sched_dev =  pd.read_sql(sched_dev_sql, mssql_engine,index_col='jurisdiction_id')\n",
    "# print sched_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_compare = units_by_city.join(sr13_forecast)\n",
    "forecast_compare = forecast_compare.join(sched_dev)\n",
    "forecast_compare['forecast_sr14'] = forecast_compare['sr14_no_sched_dev'] + forecast_compare['sr14_sched_dev']\n",
    "forecast_compare['diff'] =  forecast_compare['forecast_sr14'] - forecast_compare['forecast_sr13']\n",
    "print forecast_compare[['forecast_sr14','forecast_sr13','diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_compare.reset_index(inplace=True)\n",
    "forecast_compare['jurisdiction_id'] = forecast_compare['jurisdiction_id'].astype(str)\n",
    "x = forecast_compare.append(forecast_compare.sum(numeric_only=True), ignore_index=True)\n",
    "x.at[19, 'jurisdiction_id'] = 'totals'\n",
    "x.set_index('jurisdiction_id',inplace=True)\n",
    "cols = ['forecast_sr14','forecast_sr13','diff']\n",
    "x[cols] = x[cols].apply(pd.to_numeric, errors='coerce', axis=1,downcast='integer')\n",
    "# print x.dtypes\n",
    "print x[['forecast_sr14','forecast_sr13','diff']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of units added in simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print previous_run.units_added.sum()\n",
    "print units_added_df.units_added.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicated parcel ids (developed over more than one year)\n",
    "duplicated_parcels =  units_added_df[units_added_df.duplicated(['parcel_id'],keep=False)].sort_values(by='parcel_id')\n",
    "print duplicated_parcels.head()\n",
    "duplicated_parcels_count = pd.DataFrame({'count_parcels': duplicated_parcels.groupby([\"parcel_id\"]).size()})\n",
    "duplicated_parcels_count.sort_values(by='count_parcels',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_parcels_count['count_sum'] = duplicated_parcels_count.count_parcels -  1\n",
    "print('\\nNumber of parcels with units built over multiple years:')\n",
    "print len(duplicated_parcels_count)\n",
    "print('\\nNumber of extra rows (some parcels have units added in 2 years, some in 3 yrs:')\n",
    "print duplicated_parcels_count['count_sum'].sum()\n",
    "# print duplicated_parcels_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "units_by_parcel = pd.DataFrame({'total_units_added': units_added_df.groupby([\"parcel_id\"]).\n",
    "                                units_added.sum()}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_by_parcel.set_index('parcel_id',inplace=True)\n",
    "print units_by_parcel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(units_by_parcel)\n",
    "print len(units_added_df)\n",
    "# print len(units_added_df) - duplicated_parcels_count.count_parcels.sum() \n",
    "print len(units_added_df) - 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print units_by_parcel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Number of parcels with capacity that have no units added:\"\n",
    "print len(parcels_df[~parcels_df.index.isin(units_by_parcel.index)].reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Number of parcels that have units added but no capacity:\"\n",
    "print len(units_by_parcel[~units_by_parcel.index.isin(parcels_df.index)].reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print parcels_df.head()\n",
    "#print units_by_parcel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels_plus_capacity = parcels_df.join(units_by_parcel)\n",
    "print parcels_plus_capacity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parcels_plus_capacity['diff'] = parcels_plus_capacity['capacity'] - parcels_plus_capacity['total_units_added']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parcels_plus_capacity.to_csv('data/pcap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "households_sql = '''\n",
    "  SELECT sum(hh) AS hh,yr\n",
    "  FROM isam.demographic_output.summary\n",
    "  WHERE sim_id = 1004 and yr > 2019\n",
    "  GROUP BY yr\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buildings_sql = '''\n",
    "SELECT  SUM(COALESCE(residential_units,0)) AS residential_units\n",
    "FROM urbansim.urbansim.building\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sched_dev_sql = '''\n",
    "SELECT  SUM(COALESCE(capacity,0)) \n",
    "FROM urbansim.urbansim.parcel\n",
    "WHERE site_id is NOT NULL and capacity > 0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_df =  pd.read_sql(households_sql, mssql_engine)\n",
    "du_df =  pd.read_sql(buildings_sql, mssql_engine)\n",
    "sh_df =  pd.read_sql(sched_dev_sql, mssql_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh = hh_df.loc[hh_df.yr==2050].hh.values[0]\n",
    "du = int(du_df.values)\n",
    "sched_dev_capacity = int(sh_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "units_needed = hh - du - sched_dev_capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print '\\nHouseholds 2050:'\n",
    "print hh\n",
    "print '\\nResidential units base year:'\n",
    "print du\n",
    "print '\\nSched dev:'\n",
    "print sched_dev_capacity\n",
    "print '\\nUnits needed = Households 2050 - Residential units base year - Sched dev'\n",
    "print '\\nUnits needed:'\n",
    "print units_needed\n",
    "print '\\nTotal units added:'\n",
    "print int(units_added_df.units_added.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_diff = hh_df.set_index('yr').diff()\n",
    "hh_diff.reset_index(inplace=True)\n",
    "ts = pd.Series(hh_diff['hh'].values, index=hh_diff['yr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of new households by year \n",
    "ts.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of units added by year\n",
    "df = units_added_df.groupby(['year_simulation'])['units_added'].sum()\n",
    "df.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "units_added_df.sort_values(by='units_added',inplace=True,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print units_added_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print units_added_df.loc[units_added_df.parcel_id==9002470]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Total households by year\n",
    "df = hh_df.groupby(['yr'])['hh'].sum()\n",
    "df.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
